<!DOCTYPE html>
<html lang="zh-tw">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="AEpTGuQAkxnTOlmfF4INDna3S660LxrkyZ4BQzVbRSw">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"littlebees.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":true,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="動機 平行的思考">
<meta property="og:type" content="article">
<meta property="og:title" content="Parallel Thinking">
<meta property="og:url" content="https://littlebees.github.io/2022/01/Parallel/index.html">
<meta property="og:site_name" content="記事本">
<meta property="og:description" content="動機 平行的思考">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="https://i.imgur.com/xazEgFP.png">
<meta property="og:image" content="https://i.imgur.com/WtmxKpp.png">
<meta property="og:image" content="https://i.imgur.com/1BAOOcI.png">
<meta property="og:image" content="https://i.imgur.com/pSosatq.png">
<meta property="og:image" content="https://i.imgur.com/KaxmLXe.png">
<meta property="og:image" content="https://i.imgur.com/skEWOYm.png">
<meta property="og:image" content="https://i.imgur.com/WgkdkAY.png">
<meta property="og:image" content="https://i.imgur.com/bLqxzci.png">
<meta property="og:image" content="https://i.imgur.com/SAkjaRH.png">
<meta property="og:image" content="https://i.imgur.com/Xl2kT4r.png">
<meta property="og:image" content="https://i.imgur.com/GgrGrNh.png">
<meta property="og:image" content="https://i.imgur.com/2CkRyXO.png">
<meta property="og:image" content="https://i.imgur.com/GmbmSlh.png">
<meta property="og:image" content="https://i.imgur.com/rgjIZBu.png">
<meta property="og:image" content="https://i.imgur.com/rFcemmQ.png">
<meta property="og:image" content="https://i.imgur.com/9m990mT.png">
<meta property="og:image" content="https://i.imgur.com/3MltPh3.png">
<meta property="og:image" content="https://i.imgur.com/Y4sfx64.png">
<meta property="og:image" content="https://i.imgur.com/lCEPIqv.png">
<meta property="og:image" content="https://i.imgur.com/qfmOova.png">
<meta property="og:image" content="https://i.imgur.com/bipcZbK.png">
<meta property="og:image" content="https://i.imgur.com/Y5FnG7O.png">
<meta property="og:image" content="https://i.imgur.com/uDo2iLn.png">
<meta property="og:image" content="https://i.imgur.com/6DBNRtv.png">
<meta property="og:image" content="https://i.imgur.com/LnmsK9k.png">
<meta property="og:image" content="https://i.imgur.com/QY4cmRT.png">
<meta property="og:image" content="https://i.imgur.com/R6Zrm30.png">
<meta property="og:image" content="https://i.imgur.com/AV6N7D6.png">
<meta property="og:image" content="https://i.imgur.com/GlP5OdH.png">
<meta property="og:image" content="https://i.imgur.com/TsxBVxy.png">
<meta property="og:image" content="https://i.imgur.com/bXAa9X7.png">
<meta property="og:image" content="https://i.imgur.com/yGe3fV2.png">
<meta property="og:image" content="https://i.imgur.com/aOsDBlb.png">
<meta property="og:image" content="https://i.imgur.com/LbbSIdZ.png">
<meta property="og:image" content="https://i.imgur.com/lJYJwVy.png">
<meta property="og:image" content="https://i.imgur.com/GkIRVVs.png">
<meta property="og:image" content="https://i.imgur.com/baa7m0s.png">
<meta property="og:image" content="https://i.imgur.com/YsT0FTF.png">
<meta property="og:image" content="https://i.imgur.com/xUbOepe.png">
<meta property="og:image" content="https://i.imgur.com/BYlb6Lx.png">
<meta property="og:image" content="https://i.imgur.com/0CxmgBp.png">
<meta property="og:image" content="https://i.imgur.com/GLS2dNJ.png">
<meta property="og:image" content="https://i.imgur.com/uVyBfhp.png">
<meta property="article:published_time" content="2022-01-17T06:27:20.000Z">
<meta property="article:modified_time" content="2022-03-31T03:22:06.997Z">
<meta property="article:author" content="zhengcf">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.imgur.com/xazEgFP.png">

<link rel="canonical" href="https://littlebees.github.io/2022/01/Parallel/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-tw'
  };
</script>

  <title>Parallel Thinking | 記事本</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">記事本</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">寫下來，不然會忘</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-tw">
    <link itemprop="mainEntityOfPage" href="https://littlebees.github.io/2022/01/Parallel/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhengcf">
      <meta itemprop="description" content="想到什麼就寫什麼">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="記事本">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Parallel Thinking
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-01-17 14:27:20" itemprop="dateCreated datePublished" datetime="2022-01-17T14:27:20+08:00">2022-01-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-03-31 11:22:06" itemprop="dateModified" datetime="2022-03-31T11:22:06+08:00">2022-03-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/System/" itemprop="url" rel="index"><span itemprop="name">System</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/System/Parallel/" itemprop="url" rel="index"><span itemprop="name">Parallel</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="動機-662">動機</h2>
<p>平行的思考</p>
<span id="more"></span>
<h2 id="Concurrent-computing-Parallel-computing-Distributed-computing">Concurrent computing &amp; Parallel computing &amp; Distributed computing</h2>
<p>其實就共用資源、與各個計算單元之間要溝通這件事而言，他們其實差不多</p>
<p>但如果還是要分的話<br>
Parallelism: 多個core同時跑<br>
Concurrency: 因為同時/交互執行/節點失敗/節點不可靠所造成的效果(non-determinacy)</p>
<p><img src="https://i.imgur.com/xazEgFP.png" alt=""></p>
<h2 id="Parallel-computing-Distributed-computing">Parallel computing &amp; Distributed computing</h2>
<p>其實就共用資源、與各個計算單元之間要溝通這件事而言，他們其實差不多</p>
<p>但Distributed computing更重視HA的部分</p>
<h2 id="平行化就是在-Coordination">平行化就是在 =&gt; Coordination</h2>
<ul>
<li>Communication: 傳送結果到其他點</li>
<li>Load Balancing: 工作量不能差太大</li>
<li>Synchronization: 要等其他點到一定程度</li>
</ul>
<p>用一般演算法的話來說就是D&amp;Q，所以怎麼divide?</p>
<h3 id="Task-parallelism-Data-parallelism">Task-parallelism &amp; Data-parallelism</h3>
<p>Task-parallelism: 各種任務(像新年大掃除有掃廁所、清廚房…)，不同core做<br>
Data-parallelism: 不同core做類似的任務，像多段下載</p>
<p>目前沒有一個好的方式把serial prog轉成Parallel prog<br>
所以要自己寫!!</p>
<p>因為task吃題目，所以這裡只看Data-parallelism</p>
<h2 id="2-parallel-models-1-model">2 parallel models (+ 1 model)</h2>
<p>model的要素</p>
<ul>
<li>Control
<ul>
<li>如何達成平行化</li>
<li>operation之間的怎麼協調執行順序</li>
</ul>
</li>
<li>Data
<ul>
<li>那些資料是 private 是 shared</li>
<li>怎麼存取shraed data</li>
</ul>
</li>
<li>Synchronization
<ul>
<li>有哪些operation</li>
<li>那些是atomic</li>
</ul>
</li>
<li>Cost
<ul>
<li>有什麼成本</li>
</ul>
</li>
</ul>
<h3 id="Shared-Memory">Shared Memory</h3>
<ul>
<li>Control
<ul>
<li>如何達成平行化
<ul>
<li>thread當成抽象的processor</li>
<li>可以自由地創thread</li>
</ul>
</li>
<li>operation之間的怎麼協調執行順序
<ul>
<li>讀寫shared memory</li>
<li>透過Synchronization做協調(coordinate)</li>
</ul>
</li>
</ul>
</li>
<li>Data
<ul>
<li>那些資料是 private 是 shared
<ul>
<li>private: 在thread內的</li>
<li>shared: 在thread外的</li>
</ul>
</li>
<li>怎麼存取shraed data
<ul>
<li>直接讀寫mem</li>
</ul>
</li>
</ul>
</li>
<li>Synchronization
<ul>
<li>有哪些operation
<ul>
<li>Synchronization
<ul>
<li>semaphore</li>
<li>mutex</li>
<li>busy-waiting</li>
</ul>
</li>
<li>協調
<ul>
<li>condition variable</li>
</ul>
</li>
</ul>
</li>
<li>那些是atomic
<ul>
<li>就是atomic與thread操作</li>
</ul>
</li>
</ul>
</li>
<li>Cost
<ul>
<li>有什麼成本
<ul>
<li>創thread</li>
<li>context switch</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Race-Condition">Race Condition</h4>
<p>每次跑，結果可能會不同</p>
<h4 id="優缺點">優缺點</h4>
<ul>
<li>優點
<ul>
<li>溝通方式簡單
<ul>
<li>mem讀寫</li>
</ul>
</li>
</ul>
</li>
<li>缺點
<ul>
<li>需要Synchronization機制</li>
<li>不好scale</li>
<li>處理cache很頭痛 (cache Coherence)</li>
</ul>
</li>
</ul>
<h3 id="Message-passing">Message passing</h3>
<ul>
<li>Control
<ul>
<li>如何達成平行化
<ul>
<li>有許多獨立的processor</li>
</ul>
</li>
<li>operation之間的怎麼協調執行順序
<ul>
<li>send/receive pairs
<ul>
<li>在溝通時剛好完成協調</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Data
<ul>
<li>那些資料是 private 是 shared
<ul>
<li>private: processor內的資料</li>
</ul>
</li>
<li>怎麼存取shraed data
<ul>
<li>沒有shared data，要透過send/receive pairs</li>
</ul>
</li>
</ul>
</li>
<li>Synchronization
<ul>
<li>有哪些operation
<ul>
<li>不用</li>
</ul>
</li>
<li>那些是atomic
<ul>
<li>不用</li>
</ul>
</li>
</ul>
</li>
<li>Cost
<ul>
<li>有什麼成本
<ul>
<li>溝通時的delay
<ul>
<li>溝通的方式: 網路, mem</li>
<li>怎麼接收: poll, interrupt</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="優缺點-2">優缺點</h4>
<ul>
<li>優點
<ul>
<li>明確溝通</li>
<li>不用特別為cache頭痛</li>
</ul>
</li>
<li>缺點
<ul>
<li>溝通的成本很高</li>
<li>不好寫 (??)</li>
</ul>
</li>
</ul>
<h3 id="Shared-Memory-Message-passing">Shared Memory &amp; Message passing</h3>
<ul>
<li>communication Turing complete
<ul>
<li>彼此可以互相實作對方的模型</li>
</ul>
</li>
</ul>
<h3 id="除了divide，還可以一次處理多一點-Data-Parallel">除了divide，還可以一次處理多一點: Data Parallel</h3>
<p>像是array不是一次處理一個，或是讓thread分別處理每個段</p>
<p>現在是直接處理整個array!!</p>
<h2 id="Parallel-Algo的手法">Parallel Algo的手法</h2>
<ol>
<li>把任務切出來，讓其他人去做 (Divide-and-conquer)</li>
<li>讓一次處理的資料變多 (對array之類的collection操作)</li>
<li>Contraction (縮點、上rank)</li>
<li>Randomization</li>
<li>Identifying independent sets</li>
<li>Pointer jumping</li>
</ol>
<h3 id="parallel-primitives">parallel primitives</h3>
<ul>
<li>map</li>
<li>reduce: reduce, min, max, sum, …</li>
<li>scan: prefix sum</li>
<li>filter
<ul>
<li>其實是由 map, scan, map構成
<ul>
<li>map給的predicate</li>
<li>scan做prefix sum (counting sort)</li>
<li>利用 第1步與第2步的array去生array</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>從FP來的，在mapreduce後廣為人知</p>
<h3 id="Parallel-Algo的BigO">Parallel Algo的BigO</h3>
<ul>
<li>work: sequential 跑的時間複雜度 (只有一顆core)</li>
<li>span: 如果有很多core跑時，<strong>最長的</strong>時間複雜度 (有很多顆core)
<ul>
<li>怎麼樣叫Parallel，怎麼樣叫Sequential
<ul>
<li>fully Sequential: <code>for (i : range(A)) A[i] = f(A[i-1])</code>
<ul>
<li>這個span是A</li>
</ul>
</li>
<li>fully Parallel: <code>for (i : range(A)) A[i] = f(A[i])</code>
<ul>
<li>這個span是1</li>
</ul>
</li>
<li>partially Parallel: <code>for (i : range(A)) A[i] = f(A[i-sqrt(len(A))])</code>
<ul>
<li>這個span是sqrt(A)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>speed-up: work/span</li>
</ul>
<p>所以實際的時間複雜度 (Tp)，一定介於兩者之間<br>
<code>work &lt;= Tp &lt;= span</code></p>
<p>之後有個神奇公式，可以求漸近的Tp，P是核心數，<br>
<code>Tp = O(work/P + span)</code></p>
<p>這邊可以配合後面的 測量指標(尤其是Amdahl’s Law) 一起看</p>
<h4 id="例子-findMin-on-Tree">例子: findMin on Tree</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">findMin</span>(<span class="params">root</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">float</span>(<span class="string">&#x27;-inf&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">min</span>(root.data, findMin(root.left), findMin(root.right))</span><br></pre></td></tr></table></figure>
<p>work:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if n = 1</span><br><span class="line">    O(1)</span><br><span class="line">else</span><br><span class="line">    O(left) + O(right) + O(1)</span><br></pre></td></tr></table></figure>
<p>span:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if n = 1</span><br><span class="line">    O(1)</span><br><span class="line">else</span><br><span class="line">    max(O(left) + O(right)) + O(1)</span><br></pre></td></tr></table></figure>
<p>所以需要知道實際的input，才知道實際的複雜度</p>
<ul>
<li>Degenerate Tree(就是list)
<ul>
<li>work: O(n)</li>
<li>span: O(n)</li>
</ul>
</li>
<li>Perfect Tree(平衡樹)
<ul>
<li>work: O(n)</li>
<li>span: O(log n)</li>
</ul>
</li>
</ul>
<h2 id="測量指標">測量指標</h2>
<ul>
<li>speedup: serial執行的時間對上Parallel執行的時間 的比率
<ul>
<li>線性speedup
<ul>
<li>speedup 剛好等於 核心數</li>
<li>也就是隨著核心數上去速度就會上去</li>
</ul>
</li>
</ul>
</li>
<li>efficiency: speedup的比率除上核心數，也就是每個核心促進了多少進步</li>
<li>scalability: 資料量上升，核心數上升就能讓efficiency不變
<ul>
<li>Strongly scalable
<ul>
<li>核心數上升，<strong>資料量不變</strong>，efficiency不變</li>
</ul>
</li>
<li>Weakly scalable
<ul>
<li>核心數上升，<strong>資料量上升</strong>，efficiency不變</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="隨著核心數上升，performance可以提升到多少">隨著核心數上升，performance可以提升到多少?</h3>
<p>performance有兩個面向，latency與throughput</p>
<p>s是serial的比例(就是1-p)，p是parallel的比例(就是1-s)，n是核心數</p>
<p>兩個面向關注的點不同，</p>
<ul>
<li>一個是關注能減少多少時間
<ul>
<li>Amdahl’s Law
<ul>
<li><code>speedup = (s+p) / (s+(p/n)) = 1 / (s+(p/n))</code>
<ul>
<li>n帶無限，可以得到1/s</li>
</ul>
</li>
<li>假設
<ul>
<li>溝通時沒有成本</li>
<li>問題大小固定</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>一個看能多處理多少工作
<ul>
<li>Gustafson’s Law
<ul>
<li><code>(s+n*p) / (s+p) = (1-p)+n*np = 1+(n-1)*p</code></li>
<li>假設
<ul>
<li>處理時間固定</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="到處都是平行化">到處都是平行化</h2>
<h3 id="processor">processor</h3>
<h4 id="Instruction-Level-Parallelism-ILP">Instruction Level Parallelism (ILP)</h4>
<ul>
<li>讓一次處理的資料變多
<ul>
<li>指令 (把指令想像成一條長帶子)
<ul>
<li>把帶子空隙填滿: 總throughput不變，latency變小
<ul>
<li>Out of Order Execution
<ul>
<li>stall時跑指令</li>
<li>Out-of-order execution =&gt; out-of-order completion</li>
</ul>
</li>
<li>Pipelining
<ul>
<li>把工作流程分段</li>
<li>各種harzard
<ul>
<li>Structural hazards: 同時想用同一個phase</li>
<li>Data hazards
<ul>
<li>Read-after-write: 完成寫入前讀值
<ul>
<li>沒辦法在不犧牲latency的方式下處理</li>
<li>處理方式
<ul>
<li>stall</li>
</ul>
</li>
</ul>
</li>
<li>Write-after-read: 完成讀值前寫入</li>
<li>Write-after-write: 完成第一個寫入前寫入
<ul>
<li>處理方式
<ul>
<li>ooo execution
<ul>
<li>register renaming</li>
</ul>
</li>
<li>forwarding (cps)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Control hazards</li>
<li>猜、猜、猜
<ul>
<li>Speculative Execution</li>
<li>猜 分支、指令相依性、數字</li>
<li>猜錯要整個重來</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>把帶子疊到帶子上(1 x n到2 x 0.5n): 總throughput變大，latency變小
<ul>
<li>Superscalar: 可以同時跑很多指令
<ul>
<li>原本是scalar，也就是只操作一條指令/資料單位</li>
</ul>
</li>
<li>VLIW (Very Long Instruction Word): 把沒有相關的指令包在一起跑
<ul>
<li>由compiler指定什麼指令可以一起跑</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>資料
<ul>
<li>Vector Processing/SIMD (Single Instruction Multiple Data)
<ul>
<li>以array為單位去操作了 (原本是一次一個，做好幾次)</li>
<li>programmer要自己寫，compiler或是cpu不會自己轉換</li>
<li>Multimedia Extensions
<ul>
<li>把一部分的reg當成array
<ul>
<li>像把32 bits的reg當成兩個16 bits的array</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="Superscalar-VLIW">Superscalar &amp; VLIW</h5>
<p>與Superscalar差在compiler的輸出，一個是parralel，一個是serial code<br>
<img src="https://i.imgur.com/WtmxKpp.png" alt=""></p>
<p><img src="https://i.imgur.com/1BAOOcI.png" alt=""></p>
<p>所以VLIW compiler需要做binder把call分配到下面的執行單元，Superscalar是留給硬體<br>
<img src="https://i.imgur.com/pSosatq.png" alt=""></p>
<p><img src="https://i.imgur.com/KaxmLXe.png" alt=""></p>
<h4 id="Thread-Level-Parallelism-TLP">Thread-Level Parallelism (TLP)</h4>
<ul>
<li>thread origin
<ul>
<li>real processor
<ul>
<li>Hardware</li>
</ul>
</li>
<li>illusion: 在某個時間後就切到另一個thread
<ul>
<li>Hardware</li>
<li>OS</li>
<li>user-level (PL的library)</li>
</ul>
</li>
</ul>
</li>
<li>thread creation
<ul>
<li>cobegin/coend: 這塊(procedure)可以平行的跑</li>
<li>fork/join: fork出去的(procedure或function)會平行的跑</li>
<li>future: 這段code(expression)會平行的跑</li>
</ul>
</li>
<li>thread Scheduling
<ul>
<li>底層決定他什麼時候跑 (thread switch)
<ul>
<li>fine grain: thread主動交棒</li>
<li>coarse grain: thread stall, 其他thread可以跑 等等</li>
</ul>
</li>
<li>可以指定affinity</li>
<li>或是用user-level thread</li>
</ul>
</li>
<li>too many thread!
<ul>
<li>創thread要$$
<ul>
<li>mem</li>
<li>cpu的cycle</li>
</ul>
</li>
<li>Sol
<ul>
<li>thread pool或是固定thread數量</li>
<li>復用main thread
<ul>
<li>before: <code>A.fork(); B.fork(); A.join(); B.join();</code></li>
<li>after: <code>A.fork(); B.run(); A.join();</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="TLP-ILP">TLP + ILP</h5>
<p>把TLP的thread當成填充ILP發生stall的指令來源</p>
<h4 id="summary-2">summary</h4>
<p><img src="https://i.imgur.com/skEWOYm.png" alt=""></p>
<h4 id="Memory-System">Memory System</h4>
<ul>
<li>與cpu相比，ram的速度太慢了!!
<ul>
<li>Locality
<ul>
<li>8/2法則: 最常用到的只有一點點
<ul>
<li>從古至今，hardware依舊靠locality加速</li>
</ul>
</li>
<li>Temporal Locality (Locality in Time)
<ul>
<li>loop</li>
</ul>
</li>
<li>Spatial Locality (Locality in Space)
<ul>
<li>array</li>
</ul>
</li>
</ul>
</li>
<li>Memory Hierarchy
<ul>
<li>越慢的放越遠</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="hardware-Architecture">hardware Architecture</h3>
<p>把多個處理單元放在一起，一起處理問題</p>
<ul>
<li>重點是?
<ul>
<li>資源分配
<ul>
<li>有什麼處理單元? cpu? gpu?</li>
<li>多少mem</li>
</ul>
</li>
<li>communication的成本
<ul>
<li>Data access, Communication and Synchronization</li>
<li>從Power與latency (所有效能面向)，communication是最貴的部分</li>
</ul>
</li>
</ul>
</li>
<li>Architecture的分類
<ul>
<li>Single-instruction single-data (SISD)</li>
<li>Single-instruction multiple-data (SIMD)</li>
<li>Multiple-instruction multiple-data (MIMD)</li>
<li>Multiple-instruction single-data (MISD)</li>
<li><img src="https://i.imgur.com/WgkdkAY.png" alt=""></li>
</ul>
</li>
<li>總的來說
<ul>
<li><img src="https://i.imgur.com/bLqxzci.png" alt=""></li>
</ul>
</li>
</ul>
<h4 id="Shared-memory-Architectures">Shared-memory Architectures</h4>
<ul>
<li>任何cpu都能access到任何mem</li>
<li>透過mem操作溝通</li>
<li>兩種類型
<ul>
<li>
<p>Uniform Memory Access</p>
<ul>
<li>Symmetric Multiprocessor (SMP)</li>
<li>Cache Coherence
<ul>
<li>每個cpu都有自己的cache</li>
<li>如果有人改到mem的值，其他cache怎麼辦
<ul>
<li><img src="https://i.imgur.com/SAkjaRH.png" alt=""></li>
</ul>
</li>
<li>Sol: Coherence Protocol
<ul>
<li>去invalidate其他cache</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Non-Uniform Memory Access</p>
<ul>
<li>Distributed shared memory
<ul>
<li>所以access到mem的時間會有所不同!!
<ul>
<li>Coherence not Enough!!
<ul>
<li>傳輸有delay的話…</li>
<li><img src="https://i.imgur.com/Xl2kT4r.png" alt=""></li>
</ul>
</li>
<li>Sol: Memory Consistency Model
<ul>
<li>執行某個記憶體操作，誰看的到這個改動</li>
<li>Sequential Consistency
<ul>
<li>每個指令都是atomic!!</li>
</ul>
</li>
<li>還有其他的，在介紹lockfree時再提</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><img src="https://i.imgur.com/GgrGrNh.png" alt=""></p>
</li>
</ul>
</li>
</ul>
<h5 id="Coherence-Consistency">Coherence &amp; Consistency</h5>
<ul>
<li>Coherence
<ul>
<li>read會拿到<strong>什麼值</strong>
<ul>
<li>別人寫了，(cache)拿到的值是不是對的</li>
</ul>
</li>
<li>behavior to same location</li>
</ul>
</li>
<li>Consistency
<ul>
<li><strong>什麼時候</strong>會拿到寫入的值
<ul>
<li>寫之後，要一直read到某一次或是第一次之後才會看到</li>
</ul>
</li>
<li>behavior to other locations</li>
</ul>
</li>
</ul>
<h4 id="Distributed-memory-Architectures">Distributed-memory Architectures</h4>
<ul>
<li>processor有自己的mem</li>
<li>mem不與其他人共享</li>
<li><img src="https://i.imgur.com/2CkRyXO.png" alt=""></li>
</ul>
<h3 id="software-Programming">software Programming</h3>
<h4 id="Shared-Memory-Model">Shared-Memory Model</h4>
<ul>
<li>變數(mem)分成shared與private</li>
<li>Explicit v.s. Implicit Threads Programming
<ul>
<li>Explicit: pthread
<ul>
<li>創thread
<ul>
<li>用API創</li>
<li>programmer創thread與管理thread</li>
</ul>
</li>
<li>分配工作
<ul>
<li>programmer自己寫</li>
</ul>
</li>
<li>sync (等待thread完成)
<ul>
<li>手動join</li>
</ul>
</li>
</ul>
</li>
<li>Implicit: openMP
<ul>
<li>創thread
<ul>
<li>用directives</li>
<li>runtime創thread與管理thread</li>
</ul>
</li>
<li>分配工作
<ul>
<li>用directives</li>
</ul>
</li>
<li>sync (等待thread完成)
<ul>
<li>在區塊結束的地方等</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Nondeterminism: race condition
<ul>
<li>mutex</li>
<li>busy-waiting</li>
<li>semaphore</li>
<li>Transactional memory</li>
</ul>
</li>
<li>Thread Safety
<ul>
<li>serial function在multi-thread能不能正常跑</li>
<li>反例: strtok
<ul>
<li>他有static去存目前string處理到哪邊，如果被多thread call…</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Distributed-Memory-Model">Distributed-Memory Model</h4>
<ul>
<li>process有自己的mem</li>
<li>mem不與其他人共享</li>
<li>各個process之間有rank作類似addr的功用</li>
<li>有另外的超能力
<ul>
<li>Broadcast: 把val推到其他process</li>
<li>Reduction: 把其他process的output整合</li>
</ul>
</li>
<li>One-Sided Communication
<ul>
<li>只更新一個mem的值
<ul>
<li>跟新local，from remote process</li>
<li>跟新remote，from local process</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Programming-Hybrid-Systems">Programming Hybrid Systems</h4>
<ul>
<li>Partitioned Global Address Space Languages
<ul>
<li>allow the user to use some shared-memory techniques
<ul>
<li>for programming distributed-memory hardware</li>
</ul>
</li>
<li>跨local的mem access十分慢!!</li>
</ul>
</li>
</ul>
<h2 id="Shared-memory-programing">Shared memory programing</h2>
<h3 id="3-synchronization-scenarios">3 synchronization scenarios</h3>
<h4 id="critical-section">critical section</h4>
<p>多thread共同修改某一變數，就是critical section</p>
<h5 id="Busy-waiting">Busy-waiting</h5>
<ul>
<li>可能是reorder的受害者  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">y = <span class="built_in">f</span>(id)</span><br><span class="line"><span class="keyword">while</span> (flag != id) ;</span><br><span class="line">x += y</span><br><span class="line">flag++</span><br><span class="line"></span><br><span class="line"><span class="comment">// order</span></span><br><span class="line">y = <span class="built_in">f</span>(id)</span><br><span class="line">x += y</span><br><span class="line"><span class="keyword">while</span> (flag != id) ;</span><br><span class="line">flag++</span><br></pre></td></tr></table></figure>
</li>
<li>會把一顆cpu吃掉 (spin lock)</li>
</ul>
<h5 id="mutex">mutex</h5>
<p>就是mutex，在real time可以有priority promotion處理priority inversion</p>
<h5 id="Semaphore">Semaphore</h5>
<p>acc就是還有多少個空位的意思</p>
<p>原本: acc + queue<br>
posix: acc</p>
<h4 id="Semaphores-vs-Mutexes">Semaphores vs Mutexes</h4>
<p>Semaphore不管ownership，只要有人call semaphore，semaphore就會變</p>
<h4 id="Producer-Consumer-Synchronization-no-critical-section">Producer-Consumer Synchronization (no critical section)</h4>
<ul>
<li>沒有critical section
<ul>
<li>No competition synchronization</li>
<li>為了合作而synchronization (Cooperation synchronization)</li>
</ul>
</li>
</ul>
<h4 id="barrier">barrier</h4>
<p>要所有thread在同一時間啟動(或是停在同一個點)</p>
<p>像是debug或是計時會用到</p>
<h5 id="用busy-waiting與mutex">用busy-waiting與mutex</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mutex.lock()</span><br><span class="line">acc += <span class="number">1</span></span><br><span class="line">mutex.unlock()</span><br><span class="line"><span class="keyword">while</span> acc &lt; cnt_of_threads:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<ul>
<li>吃爆cpu(busy waiting)</li>
<li>怎麼做第2個barrier?
<ul>
<li>reset acc? 要考慮有沒有reset acc對</li>
</ul>
</li>
</ul>
<h5 id="用Semaphores">用Semaphores</h5>
<p>一個數有幾個process (count_sem, 1) (其實應該可以用atomic)</p>
<p>一個數負責停下process (barrier_sem, 0)</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sem_wait</span>(&amp;count_sem);</span><br><span class="line"><span class="keyword">if</span> (counter == thread_count−<span class="number">1</span>) &#123;</span><br><span class="line">    counter = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">sem_post</span>(&amp;count_sem);</span><br><span class="line">    <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; thread_count−<span class="number">1</span>; j++)</span><br><span class="line">        <span class="built_in">sem_post</span>(&amp;barrier_sem);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    counter++;</span><br><span class="line">    <span class="built_in">sem_post</span>(&amp;count_sem);</span><br><span class="line">    <span class="built_in">sem_wait</span>(&amp;barrier_sem);</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<h5 id="用condition-variable">用condition variable</h5>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">pthread_mutex_lock</span>(&amp;mutex);</span><br><span class="line">counter++;</span><br><span class="line"><span class="keyword">if</span> (counter == thread_count) &#123;</span><br><span class="line">    counter = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">pthread_cond_broadcast</span>(&amp;cond_var);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">pthread_cond_wait</span>(&amp;cond_var, &amp;mutex) ;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">pthread_mutex_unlock</span>(&amp;mutex);</span><br></pre></td></tr></table></figure>
<h3 id="lock其實很貴">lock其實很貴</h3>
<p>假設要做一個multi-thread的linked list</p>
<ol>
<li>所有動作用lock包
<ul>
<li>那根本就是serial</li>
</ul>
</li>
<li>每個node放lock
<ul>
<li>lock要空間!!</li>
<li>實作十分複雜</li>
<li>明明只要read卻還要跟別人搶lock!?
<ul>
<li>所以這個效能是所有case中最爛的</li>
</ul>
</li>
</ul>
</li>
<li>read-write lock
<ul>
<li>可以與1一樣但是read的成本變小了
<ul>
<li>write多，總體效果與1一樣</li>
<li>read多，效果比1好</li>
</ul>
</li>
<li>還可以保護write</li>
</ul>
</li>
</ol>
<h3 id="關於cache">關於cache</h3>
<h4 id="cache-miss">cache miss</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">Pth_mat_vect</span><span class="params">(<span class="keyword">void</span>* rank)</span> </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">for</span> (i = my_first_row; i &lt;= my_last_row; i++) &#123;</span><br><span class="line">        y[i] = <span class="number">0.0</span>; <span class="comment">// HERE</span></span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j++)</span><br><span class="line">            y[i] += A[i*n+j]*x[j]; <span class="comment">// HERE</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125; <span class="comment">/* Pth_mat_vect */</span></span><br></pre></td></tr></table></figure>
<p>cacheline是64 bytes</p>
<ol>
<li>如果y的範圍太大，寫入會失敗 (write-misses)</li>
<li>如果x的範圍太大，寫入會失敗 (read-misses)</li>
</ol>
<h4 id="false-sharing">false sharing</h4>
<p>假設上面程式的y，剛好可以都放入cacheline，但是只要cacheline的值被某個thread改變，其他thread要access資料時cacheline就要重拿資料(Cache Coherence)，而這邊明明都是y，如果一直有thread寫資料…</p>
<p>所以可以想見，cacheline會一直重拿，但是明明大部分的cache(y)是對的!!</p>
<p>另一個情況是task上編號(rank)，這樣在shared mem中就不會衝突，但因為false sharing就算把thread加上去，效能也沒有隨之變好</p>
<ol>
<li>加padding把cacheline塞滿
<ul>
<li><code>sum[id][pad]</code></li>
</ul>
</li>
<li>用syncronization包成一個變數!!
<ul>
<li><code>atomic_int sum</code></li>
</ul>
</li>
</ol>
<h3 id="Reordering-Memory">Reordering Memory</h3>
<p><img src="https://i.imgur.com/GmbmSlh.png" alt=""></p>
<ul>
<li>再一次，memory consistency model
<ul>
<li>sequentially consistent
<ul>
<li>program order == code order == commit order</li>
</ul>
</li>
<li>Relaxed Consistency
<ul>
<li>把指令分成
<ul>
<li>data(write, read)
<ul>
<li>不保證順序</li>
</ul>
</li>
<li>sync (mem barrier, volatile, atomic, fork/join…)
<ul>
<li>保證順序!!
<ul>
<li>S -&gt; S</li>
<li>S -&gt; W/R</li>
<li>W/R -&gt; S</li>
</ul>
</li>
<li>mem barrier (在openMP叫flush)
<ul>
<li>flush之前的變數(在flush有用到的部分)會被commit (所以flush中一定看的到)
<ul>
<li>read mem barrier</li>
</ul>
</li>
<li>flush之後的變數(在flush有用到的部分)，會看到在flush中做出的結果
<ul>
<li>write mem barrier</li>
</ul>
</li>
<li>flush中不會reorder</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="單論Synchronization">單論Synchronization</h3>
<ul>
<li>我們的敵人
<ul>
<li>race condition: 泛指跑好幾次可能出現不同的結果
<ul>
<li>data race: 對同一個變數修改</li>
</ul>
</li>
<li>reorder (講義叫Bad interleavings)
<ul>
<li><code>a = 1; b = 2</code> 與 <code>b = 2; a = 1;</code>
<ul>
<li>在compiler或是cpu眼中是可以reorder的!!
<ul>
<li>看arch的規定</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>工具
<ul>
<li>保持Atomicity (critical section)
<ul>
<li>mutex，但有很多細節</li>
</ul>
</li>
</ul>
</li>
<li>新的敵人
<ul>
<li>deadlock
<ul>
<li>Dining Philosophers (為lock上順序!!)</li>
</ul>
</li>
<li>Time-Of-Check-To-Time-Of-Use
<ul>
<li><code>if (checkA()) &#123; execA(); &#125;</code></li>
<li>有人在checkA成功後，到執行execA之前，被其他thread做到事的話…
<ul>
<li>換言之，if的block中，不能信任有確認過的條件了</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>解法
<ul>
<li>Thread-Local Memory
<ul>
<li>不用share的資料就copy</li>
</ul>
</li>
<li>Immutable Memory
<ul>
<li>沒有write，沒有race condition或是data race</li>
</ul>
</li>
<li>但我真的需要改 (要用mutex了qq)
<ul>
<li>Use Consistent Locking
<ul>
<li>用同樣的lock到所有有關的地方</li>
<li>好好記錄為什麼需要這個lock</li>
<li>用lock去割出 shared-and-mutable locations
<ul>
<li>lock-oriented</li>
</ul>
</li>
</ul>
</li>
<li>Start With Fewer Locks (Coarse-Grained)
<ul>
<li>除非contention太嚴重才讓lock變多 (Fine-Grained)</li>
</ul>
</li>
<li>Keep Critical Sections Small
<ul>
<li>Critical Sections太長: 效能差</li>
<li>Critical Sections太短: race condition (可以看到中間狀態)</li>
</ul>
</li>
<li>Think About Atomicity
<ul>
<li>想想什麼動作應該放在一起
<ul>
<li>像Time-Of-Check-To-Time-Of-Use</li>
<li>不是data race也不是race condition</li>
<li>但就是出事，所以應該把if與動作綁在一起</li>
</ul>
</li>
</ul>
</li>
<li>Use Libraries</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/rgjIZBu.png" alt=""></p>
<h2 id="Message-passing-programing">Message passing programing</h2>
<h3 id="Point-to-Point-Communication">Point to Point Communication</h3>
<p>Communication透過recv與send執行</p>
<p>message會傳</p>
<ul>
<li>sender的rank</li>
<li>receiver的rank</li>
<li>communicator (MPI的網路)</li>
<li>tag: 使用者指定的tag</li>
<li>data</li>
</ul>
<p>下面是standard 的傳送方式<br>
<code>sender buf --&#123;copy&#125;--&gt; system buffer --&#123;network&#125;--&gt; system buffer --&#123;copy&#125;--&gt; receiver buf</code></p>
<h3 id="communication-modes">communication modes</h3>
<h4 id="blocking">blocking</h4>
<p>blocking的理由是</p>
<ul>
<li>
<p>等handshake</p>
<ul>
<li>Synchronous</li>
</ul>
</li>
<li>
<p>等copy</p>
<ul>
<li>所有類型都要等</li>
<li>從sender buffer 到 receiver buffer
<ul>
<li>Synchronous</li>
<li>Ready</li>
</ul>
</li>
<li>從sender buffer 到 對面的system buffer 到 receiver buffer
<ul>
<li>Standard(資料小)</li>
</ul>
</li>
<li>從sender buffer 到 自己指定的 buffer 到 receiver buffer
<ul>
<li>Buffered</li>
</ul>
</li>
</ul>
</li>
<li>
<p>沒copy到別的buffer (sender buf =&gt; receiver buf)</p>
<ul>
<li>Synchronous: 一般的tcp
<ol>
<li>ssend送msg到recv說我要傳，之後等</li>
<li>recv送msg，之後等</li>
<li>handshake好了，可以送了，兩邊等到完成</li>
</ol>
<ul>
<li><img src="https://i.imgur.com/rFcemmQ.png" alt=""></li>
</ul>
</li>
<li>Ready: 類似reverse tunnel
<ol>
<li>recv送msg，之後等</li>
<li>rsend看有沒有recv的msg，有，開送，兩邊等到完成；沒有，報錯退出</li>
</ol>
<ul>
<li><img src="https://i.imgur.com/9m990mT.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li>
<p>copy到別的buffer</p>
<ul>
<li>Buffered: 先copy到自己指定的mem (in sender)
<ol>
<li>bsend把資料copy到自己指定的mem，copy完退出</li>
<li>收到recv的msg，開送</li>
</ol>
<ul>
<li><img src="https://i.imgur.com/3MltPh3.png" alt=""></li>
</ul>
</li>
<li>Standard:
<ul>
<li>資料小: copy到system buffer (in receiver)
<ol>
<li>send把資料送到對面的system buffer，等到送完</li>
<li>recv直接從system buffer copy到receiver buf，等到copy完</li>
</ol>
<ul>
<li><img src="https://i.imgur.com/Y4sfx64.png" alt=""></li>
</ul>
</li>
<li>資料大: 就變成Synchronous
<ul>
<li><img src="https://i.imgur.com/lCEPIqv.png" alt=""></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="non-blocking">non-blocking</h4>
<ol>
<li>isend會開始送，但是不會等，馬上return
<ul>
<li>用test看目前狀態，wait去等他完成</li>
</ul>
</li>
<li>irecv如果好了就會收，但是不會等，馬上return
<ul>
<li>用test看目前狀態，wait去等他完成</li>
</ul>
</li>
</ol>
<p>剩下就是Standard(資料小)</p>
<p><img src="https://i.imgur.com/qfmOova.png" alt=""></p>
<p>可以想像成傳資料時開thread!!</p>
<h3 id="deadlock-對，還是有">deadlock (對，還是有)</h3>
<p>send 與 recv 要成對出現</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (rank == <span class="number">0</span>) &#123;</span><br><span class="line">    err = <span class="built_in">MPI_Send</span>(sendbuf, count, datatype, <span class="number">1</span>, tag, comm);</span><br><span class="line">    err = <span class="built_in">MPI_Recv</span>(recvbuf, count, datatype, <span class="number">1</span>, tag, comm, &amp;status);</span><br><span class="line">&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">    err = <span class="built_in">MPI_Send</span>(sendbuf, count, datatype, <span class="number">0</span>, tag, comm);</span><br><span class="line">    err = <span class="built_in">MPI_Recv</span>(recvbuf, count, datatype, <span class="number">0</span>, tag, comm, &amp;status);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="解法-swap">解法: swap</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (rank == <span class="number">0</span>) &#123;</span><br><span class="line">    err = <span class="built_in">MPI_Send</span>(sendbuf, count, datatype, <span class="number">1</span>, tag, comm);</span><br><span class="line">    err = <span class="built_in">MPI_Recv</span>(recvbuf, count, datatype, <span class="number">1</span>, tag, comm, &amp;status);</span><br><span class="line">&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">    err = <span class="built_in">MPI_Recv</span>(recvbuf, count, datatype, <span class="number">0</span>, tag, comm, &amp;status);</span><br><span class="line">    err = <span class="built_in">MPI_Send</span>(sendbuf, count, datatype, <span class="number">0</span>, tag, comm);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="解法-non-blocking">解法: non-blocking</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (rank == <span class="number">0</span>) &#123;</span><br><span class="line">    err = <span class="built_in">MPI_Isend</span>(sendbuf, count, datatype, <span class="number">1</span>, tag, comm, &amp;req);</span><br><span class="line">    err = <span class="built_in">MPI_Irecv</span>(recvbuf, count, datatype, <span class="number">1</span>, tag, comm);</span><br><span class="line">    err = <span class="built_in">MPI_Wait</span>(req, &amp;status);</span><br><span class="line">&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">    err = <span class="built_in">MPI_Isend</span>(sendbuf, count, datatype, <span class="number">0</span>, tag, comm, &amp;req);</span><br><span class="line">    err = <span class="built_in">MPI_Irecv</span>(recvbuf, count, datatype, <span class="number">0</span>, tag, comm);</span><br><span class="line">    err = <span class="built_in">MPI_Wait</span>(req, &amp;status);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="CUDA">CUDA</h2>
<p><img src="https://i.imgur.com/bipcZbK.png" alt=""></p>
<h3 id="cpu-vs-gpu">cpu vs gpu</h3>
<p><img src="https://i.imgur.com/Y5FnG7O.png" alt=""><br>
<img src="https://i.imgur.com/uDo2iLn.png" alt=""><br>
<img src="https://i.imgur.com/6DBNRtv.png" alt=""><br>
<img src="https://i.imgur.com/LnmsK9k.png" alt=""></p>
<ul>
<li>
<p>cpu: Latency</p>
<ul>
<li>大cache
<ul>
<li>降低mem延遲</li>
</ul>
</li>
<li>複雜的control邏輯
<ul>
<li>branch prediction</li>
<li>data forwarding</li>
</ul>
</li>
<li>計算能力(ALU)強
<ul>
<li>降低operation延遲</li>
</ul>
</li>
<li>在sequential code快</li>
<li><img src="https://i.imgur.com/QY4cmRT.png" alt=""></li>
</ul>
</li>
<li>
<p>gpu: Throughput</p>
<ul>
<li>小cache
<ul>
<li>增加mem的throughput</li>
</ul>
</li>
<li>簡易的control邏輯
<ul>
<li>NO branch prediction</li>
<li>NO data forwarding</li>
</ul>
</li>
<li>計算能力(ALU)弱(省能源)
<ul>
<li>延遲高，但是可以pipeline達成高throughput
<ul>
<li>所以有<strong>很多</strong>thread</li>
</ul>
</li>
</ul>
</li>
<li>在parallel code快</li>
<li><img src="https://i.imgur.com/R6Zrm30.png" alt=""></li>
</ul>
</li>
</ul>
<h3 id="gpu">gpu</h3>
<p>下面是gpu在arch上的特點<br>
<img src="https://i.imgur.com/AV6N7D6.png" alt=""><br>
<img src="https://i.imgur.com/GlP5OdH.png" alt=""><br>
<img src="https://i.imgur.com/TsxBVxy.png" alt=""><br>
<img src="https://i.imgur.com/bXAa9X7.png" alt=""><br>
<img src="https://i.imgur.com/yGe3fV2.png" alt=""></p>
<h3 id="CUDA-Parallel-Computing-Platform">CUDA: Parallel Computing Platform</h3>
<p><img src="https://i.imgur.com/aOsDBlb.png" alt=""><br>
<img src="https://i.imgur.com/LbbSIdZ.png" alt=""></p>
<h3 id="CUDA-Heterogeneous-Programming">CUDA: Heterogeneous Programming</h3>
<p><img src="https://i.imgur.com/lJYJwVy.png" alt=""><br>
<img src="https://i.imgur.com/GkIRVVs.png" alt=""><br>
<img src="https://i.imgur.com/baa7m0s.png" alt=""></p>
<p>gpu叫<em>device</em><br>
控制的cpu叫<em>host</em><br>
各自有自己的mem，而跑在device上的function(thread)叫kernel<br>
<img src="https://i.imgur.com/YsT0FTF.png" alt=""><br>
<img src="https://i.imgur.com/xUbOepe.png" alt=""><br>
<img src="https://i.imgur.com/BYlb6Lx.png" alt=""></p>
<h4 id="Thread-Hierarchies">Thread Hierarchies</h4>
<p>grid有很多block，block(wrap)有很多thread，block中的thread可以共享資料，也同時啟動(迴避掉sync的問題)，跑同一個指令</p>
<p>不同block的thread不能合作，同時以wrap為單位做schedule</p>
<p>At any time, only one of the warps is executed by SM</p>
<p><img src="https://i.imgur.com/0CxmgBp.png" alt=""></p>
<h5 id="Thread-Synchronization">Thread Synchronization</h5>
<ul>
<li>可以用<code> __syncthreads</code>創barrier</li>
<li>atomic</li>
</ul>
<h4 id="Memory-Model">Memory Model</h4>
<p><img src="https://i.imgur.com/GLS2dNJ.png" alt=""><br>
<img src="https://i.imgur.com/uVyBfhp.png" alt=""></p>
<h2 id="lockfree-2">lockfree</h2>
<p>無論當前處於什麼狀態，只要運行足夠長的時間，至少有一個 process 能取得進展或完成其操作<br>
像是Real-time的狀況，有mutex就有可能發生priority inversion</p>
<p>或是說，絕對不可能會有deadlock程式，也就是沒有lock的程式</p>
<h3 id="作法-5">作法</h3>
<p>如果不能lock，就只能busy-waiting(或是cpu有特別指令)</p>
<p>做test-and-set，fetch-and-add，compare-and-swap，來確認改之前與改之後的值一不一樣，一樣就寫，不一樣繼續等</p>
<h4 id="少了lock之後">少了lock之後</h4>
<p>lock有一個很重要的性質，他是memory model的sync指令，所以不會被reorder</p>
<p>但現在不能用lock，所以要注意兩個東西</p>
<ol>
<li>cpu的memory model
<ul>
<li>不同架構的cpu在不同case會做reorder的case不一樣</li>
<li><span class="exturl" data-url="aHR0cHM6Ly9wcmVzaGluZy5jb20vMjAxMjA5MzAvd2Vhay12cy1zdHJvbmctbWVtb3J5LW1vZGVscy8=">Weak vs. Strong Memory Models<i class="fa fa-external-link-alt"></i></span></li>
</ul>
</li>
<li>怎麼下memory barrier (Acquire and Release Semantics)
<ul>
<li>得自己把不能reorder的範圍畫出來</li>
<li><span class="exturl" data-url="aHR0cHM6Ly9wcmVzaGluZy5jb20vMjAxMjA5MTMvYWNxdWlyZS1hbmQtcmVsZWFzZS1zZW1hbnRpY3Mv">Acquire and Release Semantics<i class="fa fa-external-link-alt"></i></span>
<ul>
<li>有些programming language有提供memory model!!
<ul>
<li>可以不用直接調用memory barrier，改用volatile
<ul>
<li>謝謝JAVA</li>
<li><a href="/2021/06/mem-models/">我之前的記憶體模型筆記</a></li>
</ul>
</li>
<li><span class="exturl" data-url="aHR0cHM6Ly9wcmVzaGluZy5jb20vMjAxMzA3MDIvdGhlLWhhcHBlbnMtYmVmb3JlLXJlbGF0aW9uLw==">The Happens-Before Relation<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9wcmVzaGluZy5jb20vMjAxMzA4MjMvdGhlLXN5bmNocm9uaXplcy13aXRoLXJlbGF0aW9uLw==">The Synchronizes-With Relation<i class="fa fa-external-link-alt"></i></span></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="ABA問題">ABA問題</h3>
<p>前面是看值一樣就當成沒改，但這是把資料與時間兩件式混在一起，所以有了ABA，也就是看起來沒換，但其實被人換過，只是資料剛好長的一樣</p>
<p>所以要多一個變數紀錄時間，有改就要遞增；與read-write lock一樣</p>
<h3 id="wait-free">wait-free</h3>
<p>就前面看到的，lockfree可能讓process無限的等(飢餓)，但是wait-free可以在有限的次數讓process動<br>
但超難，pass</p>
<p><span class="exturl" data-url="aHR0cDovL3d3dy5jcy50ZWNobmlvbi5hYy5pbC9+ZXJlei9QYXBlcnMvd2ZxdXF1ZS1wcG9wcC5wZGY=">Wait-Free Queues With Multiple Enqueuers and Dequeuers<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="TODO-8">TODO</h2>
<ul>
<li>wait-free</li>
<li>Algorithms Sequential &amp; Parallel: A Unified Approach
<ul>
<li>這我不確定，但是因為他比較新就放這裡</li>
</ul>
</li>
<li>An introduction to parallel algorithms (jaja)
<ul>
<li>這裡面提到 Parallel Algo的手法 中提到的與沒有提到的手法</li>
</ul>
</li>
</ul>
<h2 id="Ref-147">Ref</h2>
<p>An Introduction to Parallel Programming, Morgan Kaufmann<br>
<span class="exturl" data-url="aHR0cHM6Ly93d3cuY3MuY211LmVkdS9+YmxlbGxvY2gvcGFwZXJzL1BQb1BQMDkucGRm">Parallel Thinking<i class="fa fa-external-link-alt"></i></span><br>
<span class="exturl" data-url="aHR0cHM6Ly9jb3Vyc2VzLmNzLndhc2hpbmd0b24uZWR1L2NvdXJzZXMvY3NlMzMyLzE3d2kvbGVjdHVyZXMvZm9ya2pvaW4tMi9mb3Jram9pbi1hbmFseXNpcy5wZGY=">Analysis of Parallel Programs<i class="fa fa-external-link-alt"></i></span><br>
<span class="exturl" data-url="aHR0cHM6Ly9jb3Vyc2VzLmNzLndhc2hpbmd0b24uZWR1L2NvdXJzZXMvY3NlMzMyLzE3d2kvbGVjdHVyZXMvZm9ya2pvaW4tMy9zY2FuLXBhY2stc29ydGluZy5wZGY=">More Parallel Primitives and Parallel Sorting<i class="fa fa-external-link-alt"></i></span><br>
<span class="exturl" data-url="aHR0cHM6Ly9jb3Vyc2VzLmNzLndhc2hpbmd0b24uZWR1L2NvdXJzZXMvY3NlMzMyLzE3d2kvbGVjdHVyZXMvc3luY2hyb25pemF0aW9uLTEvc3luY2hyb25pemF0aW9uLnBkZg==">Synchronization<i class="fa fa-external-link-alt"></i></span><br>
<span class="exturl" data-url="aHR0cHM6Ly93d3cuY3MuY211LmVkdS9+Z3V5Yi9wYXBlcnMvc3BhYXBvZGMxNy5wZGY=">Some Sequential Algorithms are Almost Always Parallel<i class="fa fa-external-link-alt"></i></span><br>
<span class="exturl" data-url="aHR0cHM6Ly9wcmVzaGluZy5jb20vMjAxMjA2MTIvYW4taW50cm9kdWN0aW9uLXRvLWxvY2stZnJlZS1wcm9ncmFtbWluZy8=">An Introduction to Lock-Free Programming<i class="fa fa-external-link-alt"></i></span></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/01/virtualbox-net-type/" rel="prev" title="virtualbox的網路種類">
      <i class="fa fa-chevron-left"></i> virtualbox的網路種類
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/01/part-of-yaml-into-ansible/" rel="next" title="只讀一部份的yaml成ansible的變數">
      只讀一部份的yaml成ansible的變數 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8B%95%E6%A9%9F-662"><span class="nav-number">1.</span> <span class="nav-text">動機</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Concurrent-computing-Parallel-computing-Distributed-computing"><span class="nav-number">2.</span> <span class="nav-text">Concurrent computing &amp; Parallel computing &amp; Distributed computing</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Parallel-computing-Distributed-computing"><span class="nav-number">3.</span> <span class="nav-text">Parallel computing &amp; Distributed computing</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B9%B3%E8%A1%8C%E5%8C%96%E5%B0%B1%E6%98%AF%E5%9C%A8-Coordination"><span class="nav-number">4.</span> <span class="nav-text">平行化就是在 &#x3D;&gt; Coordination</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Task-parallelism-Data-parallelism"><span class="nav-number">4.1.</span> <span class="nav-text">Task-parallelism &amp; Data-parallelism</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-parallel-models-1-model"><span class="nav-number">5.</span> <span class="nav-text">2 parallel models (+ 1 model)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Shared-Memory"><span class="nav-number">5.1.</span> <span class="nav-text">Shared Memory</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Race-Condition"><span class="nav-number">5.1.1.</span> <span class="nav-text">Race Condition</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%84%AA%E7%BC%BA%E9%BB%9E"><span class="nav-number">5.1.2.</span> <span class="nav-text">優缺點</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Message-passing"><span class="nav-number">5.2.</span> <span class="nav-text">Message passing</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%84%AA%E7%BC%BA%E9%BB%9E-2"><span class="nav-number">5.2.1.</span> <span class="nav-text">優缺點</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Shared-Memory-Message-passing"><span class="nav-number">5.3.</span> <span class="nav-text">Shared Memory &amp; Message passing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%99%A4%E4%BA%86divide%EF%BC%8C%E9%82%84%E5%8F%AF%E4%BB%A5%E4%B8%80%E6%AC%A1%E8%99%95%E7%90%86%E5%A4%9A%E4%B8%80%E9%BB%9E-Data-Parallel"><span class="nav-number">5.4.</span> <span class="nav-text">除了divide，還可以一次處理多一點: Data Parallel</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Parallel-Algo%E7%9A%84%E6%89%8B%E6%B3%95"><span class="nav-number">6.</span> <span class="nav-text">Parallel Algo的手法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#parallel-primitives"><span class="nav-number">6.1.</span> <span class="nav-text">parallel primitives</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Parallel-Algo%E7%9A%84BigO"><span class="nav-number">6.2.</span> <span class="nav-text">Parallel Algo的BigO</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BE%8B%E5%AD%90-findMin-on-Tree"><span class="nav-number">6.2.1.</span> <span class="nav-text">例子: findMin on Tree</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B8%AC%E9%87%8F%E6%8C%87%E6%A8%99"><span class="nav-number">7.</span> <span class="nav-text">測量指標</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9A%A8%E8%91%97%E6%A0%B8%E5%BF%83%E6%95%B8%E4%B8%8A%E5%8D%87%EF%BC%8Cperformance%E5%8F%AF%E4%BB%A5%E6%8F%90%E5%8D%87%E5%88%B0%E5%A4%9A%E5%B0%91"><span class="nav-number">7.1.</span> <span class="nav-text">隨著核心數上升，performance可以提升到多少?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%B0%E8%99%95%E9%83%BD%E6%98%AF%E5%B9%B3%E8%A1%8C%E5%8C%96"><span class="nav-number">8.</span> <span class="nav-text">到處都是平行化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#processor"><span class="nav-number">8.1.</span> <span class="nav-text">processor</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Instruction-Level-Parallelism-ILP"><span class="nav-number">8.1.1.</span> <span class="nav-text">Instruction Level Parallelism (ILP)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Superscalar-VLIW"><span class="nav-number">8.1.1.1.</span> <span class="nav-text">Superscalar &amp; VLIW</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Thread-Level-Parallelism-TLP"><span class="nav-number">8.1.2.</span> <span class="nav-text">Thread-Level Parallelism (TLP)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#TLP-ILP"><span class="nav-number">8.1.2.1.</span> <span class="nav-text">TLP + ILP</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#summary-2"><span class="nav-number">8.1.3.</span> <span class="nav-text">summary</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Memory-System"><span class="nav-number">8.1.4.</span> <span class="nav-text">Memory System</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hardware-Architecture"><span class="nav-number">8.2.</span> <span class="nav-text">hardware Architecture</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Shared-memory-Architectures"><span class="nav-number">8.2.1.</span> <span class="nav-text">Shared-memory Architectures</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Coherence-Consistency"><span class="nav-number">8.2.1.1.</span> <span class="nav-text">Coherence &amp; Consistency</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Distributed-memory-Architectures"><span class="nav-number">8.2.2.</span> <span class="nav-text">Distributed-memory Architectures</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#software-Programming"><span class="nav-number">8.3.</span> <span class="nav-text">software Programming</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Shared-Memory-Model"><span class="nav-number">8.3.1.</span> <span class="nav-text">Shared-Memory Model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Distributed-Memory-Model"><span class="nav-number">8.3.2.</span> <span class="nav-text">Distributed-Memory Model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Programming-Hybrid-Systems"><span class="nav-number">8.3.3.</span> <span class="nav-text">Programming Hybrid Systems</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Shared-memory-programing"><span class="nav-number">9.</span> <span class="nav-text">Shared memory programing</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-synchronization-scenarios"><span class="nav-number">9.1.</span> <span class="nav-text">3 synchronization scenarios</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#critical-section"><span class="nav-number">9.1.1.</span> <span class="nav-text">critical section</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Busy-waiting"><span class="nav-number">9.1.1.1.</span> <span class="nav-text">Busy-waiting</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#mutex"><span class="nav-number">9.1.1.2.</span> <span class="nav-text">mutex</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Semaphore"><span class="nav-number">9.1.1.3.</span> <span class="nav-text">Semaphore</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Semaphores-vs-Mutexes"><span class="nav-number">9.1.2.</span> <span class="nav-text">Semaphores vs Mutexes</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Producer-Consumer-Synchronization-no-critical-section"><span class="nav-number">9.1.3.</span> <span class="nav-text">Producer-Consumer Synchronization (no critical section)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#barrier"><span class="nav-number">9.1.4.</span> <span class="nav-text">barrier</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%A8busy-waiting%E8%88%87mutex"><span class="nav-number">9.1.4.1.</span> <span class="nav-text">用busy-waiting與mutex</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%A8Semaphores"><span class="nav-number">9.1.4.2.</span> <span class="nav-text">用Semaphores</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%A8condition-variable"><span class="nav-number">9.1.4.3.</span> <span class="nav-text">用condition variable</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#lock%E5%85%B6%E5%AF%A6%E5%BE%88%E8%B2%B4"><span class="nav-number">9.2.</span> <span class="nav-text">lock其實很貴</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%97%9C%E6%96%BCcache"><span class="nav-number">9.3.</span> <span class="nav-text">關於cache</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#cache-miss"><span class="nav-number">9.3.1.</span> <span class="nav-text">cache miss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#false-sharing"><span class="nav-number">9.3.2.</span> <span class="nav-text">false sharing</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reordering-Memory"><span class="nav-number">9.4.</span> <span class="nav-text">Reordering Memory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%96%AE%E8%AB%96Synchronization"><span class="nav-number">9.5.</span> <span class="nav-text">單論Synchronization</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Message-passing-programing"><span class="nav-number">10.</span> <span class="nav-text">Message passing programing</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Point-to-Point-Communication"><span class="nav-number">10.1.</span> <span class="nav-text">Point to Point Communication</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#communication-modes"><span class="nav-number">10.2.</span> <span class="nav-text">communication modes</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#blocking"><span class="nav-number">10.2.1.</span> <span class="nav-text">blocking</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#non-blocking"><span class="nav-number">10.2.2.</span> <span class="nav-text">non-blocking</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#deadlock-%E5%B0%8D%EF%BC%8C%E9%82%84%E6%98%AF%E6%9C%89"><span class="nav-number">10.3.</span> <span class="nav-text">deadlock (對，還是有)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%A3%E6%B3%95-swap"><span class="nav-number">10.3.1.</span> <span class="nav-text">解法: swap</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%A3%E6%B3%95-non-blocking"><span class="nav-number">10.3.2.</span> <span class="nav-text">解法: non-blocking</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA"><span class="nav-number">11.</span> <span class="nav-text">CUDA</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#cpu-vs-gpu"><span class="nav-number">11.1.</span> <span class="nav-text">cpu vs gpu</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gpu"><span class="nav-number">11.2.</span> <span class="nav-text">gpu</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CUDA-Parallel-Computing-Platform"><span class="nav-number">11.3.</span> <span class="nav-text">CUDA: Parallel Computing Platform</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CUDA-Heterogeneous-Programming"><span class="nav-number">11.4.</span> <span class="nav-text">CUDA: Heterogeneous Programming</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Thread-Hierarchies"><span class="nav-number">11.4.1.</span> <span class="nav-text">Thread Hierarchies</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Thread-Synchronization"><span class="nav-number">11.4.1.1.</span> <span class="nav-text">Thread Synchronization</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Memory-Model"><span class="nav-number">11.4.2.</span> <span class="nav-text">Memory Model</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#lockfree-2"><span class="nav-number">12.</span> <span class="nav-text">lockfree</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%9C%E6%B3%95-5"><span class="nav-number">12.1.</span> <span class="nav-text">作法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B0%91%E4%BA%86lock%E4%B9%8B%E5%BE%8C"><span class="nav-number">12.1.1.</span> <span class="nav-text">少了lock之後</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ABA%E5%95%8F%E9%A1%8C"><span class="nav-number">12.2.</span> <span class="nav-text">ABA問題</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#wait-free"><span class="nav-number">12.3.</span> <span class="nav-text">wait-free</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TODO-8"><span class="nav-number">13.</span> <span class="nav-text">TODO</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Ref-147"><span class="nav-number">14.</span> <span class="nav-text">Ref</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">zhengcf</p>
  <div class="site-description" itemprop="description">想到什麼就寫什麼</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">695</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">85</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">64</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zhengcf</span>
</div>
  <div class="powered-by">Powered by <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl theme-link" data-url="aHR0cHM6Ly9tdXNlLnRoZW1lLW5leHQub3Jn">NexT.Muse</span>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 1000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'https://littlebees.github.io/2022/01/Parallel/',]
      });
      });
  </script>

</body>
</html>
