<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>圖解linux核心工作原理整理 | 記事本</title>
<meta name=keywords content="Linux"><meta name=description content="動機
都買了就讀一下"><meta name=author content="zhengcf"><link rel=canonical href=https://littlebees.github.io/2021/06/%E5%9C%96%E8%A7%A3linux%E6%A0%B8%E5%BF%83%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%95%B4%E7%90%86/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://littlebees.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://littlebees.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://littlebees.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://littlebees.github.io/apple-touch-icon.png><link rel=mask-icon href=https://littlebees.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://littlebees.github.io/2021/06/%E5%9C%96%E8%A7%A3linux%E6%A0%B8%E5%BF%83%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%95%B4%E7%90%86/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="圖解linux核心工作原理整理"><meta property="og:description" content="動機
都買了就讀一下"><meta property="og:type" content="article"><meta property="og:url" content="https://littlebees.github.io/2021/06/%E5%9C%96%E8%A7%A3linux%E6%A0%B8%E5%BF%83%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%95%B4%E7%90%86/"><meta property="og:image" content="https://littlebees.github.io/images/papermod-cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-06-13T00:46:14+00:00"><meta property="article:modified_time" content="2021-06-13T00:46:14+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://littlebees.github.io/images/papermod-cover.png"><meta name=twitter:title content="圖解linux核心工作原理整理"><meta name=twitter:description content="動機
都買了就讀一下"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://littlebees.github.io/posts/"},{"@type":"ListItem","position":2,"name":"圖解linux核心工作原理整理","item":"https://littlebees.github.io/2021/06/%E5%9C%96%E8%A7%A3linux%E6%A0%B8%E5%BF%83%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%95%B4%E7%90%86/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"圖解linux核心工作原理整理","name":"圖解linux核心工作原理整理","description":"動機 都買了就讀一下\n","keywords":["Linux"],"articleBody":"動機 都買了就讀一下\nch1 cpu至少有兩種模式 user mode kernel mode: 可以access所有記憶體 ch2 sys call 目的: 讓user space的proc調用kernel space的功能，以操作或取得底層的資源 用eval+apply的interp的角度去看，sys call就像primitive opertor proc, mem, file, IPC, network, IO, time, …. 過程: 塞sys call的編號到reg 發中斷(trap) cpu切到kernel mode 請cpu跑sys call cpu根據sys call的數字去看表 cpu跑kernel寫好的對應的handler 丟return 值，轉回去user mode 一些指令 sar -P ALL 1: (mpstat) 可以看cpu的load user% + nice%: cpu是執行在user space的時間佔比 user%: 就是一般的proc跑的 nice%: 有被調過nice有特權的proc所跑的時間 sys%: cpu是執行在kernel space的時間佔比，也就是跑sys call的時間 strace -T: 顯示proc所執行的每個sys call與花了多少時間 ldd: 看exe有link到哪些lib ch3 fork, execve: skip here exe info exe的結構有三個部分 info: 在linux是elf，會有很多資訊但對exe的結構來說重要的是 每個部份的 起點addr (fake addr) 長度 mapping後的起點addr (real addr) entry point code data 一些指令 readelf -S: 可以拿到起點addr與長度 cat /proc//maps: 可以看proc的memory mapping ch4 proc scheduler: round-robin 1個cpu只會跑1個proc 每個proc都享有相同的時間去分cpu(沒nice的話) 有nice的proc分到的cpu時間會比較多 在書中有一個程式是會fork多個proc(work load都一樣)去看分到的時間與執行狀況 總執行時間隨fork出的proc變多而跟著上升 因為throughput不變，故隨著proc數上升，proc的latency(end_time-start_time)也會上升 多cpu時會把proc往最少proc的cpu塞 一些指令 tasklet -c : 強制cmd跑在cpuid的cpu上 time ... proc state的變化大概像 run(a) | sleep | run(c) | sleep real: end_time-start_time user: user space sys: kernel space user+sys就是把所有run時間加起來 proc state executing waiting sleeping D: wait IO S: wait signal zombie ch5 virtual mem purpose: proc isolation C有ptr可以亂指，有virtual mem就指不出去 不過如果沒有ptr是不是就可以不用virtual mem? avoid mem fragment support of multiple procs implement: page table 可以當成一個存在於kernel的函數，all fake addr -\u003e all real addr demang page: lazy evaluation 直到proc寫入時kernel才去找一個real addr malloc是從先拿到的mem pool中拿addr，但mmap是sys call就是直接拿 table太大了 階層式page table 從list變成tree，all fake addr -\u003e (another table OR all real addr) huge page 把page的單位變大，讓table的item數量變少 file mapping: 把file複製到mem操作，最後在適當的時候把對file的改動寫回去 copy-on-write: 在fork時parent與child proc共用相同的Page，當其中一方改動時才複製新的，並把fake addr指到新的page上 在算proc使用的mem時會各自顯示所以佔有的mem，但是因為copy-on-write實際上的mem使用量沒那麼多 swap swap-in: mem -\u003e swap(hdd) swap-out: mem \u003c- swap(hdd) 持續 swap-in \u0026 swap-out: thrashing VSS \u0026 RSS fake mem usage \u0026 real mem usage 都有用完的機會，VSS是當table不夠時，RSS就是真的沒了 一些指令 free total: 插了多少記憶體 buff: 緩衝快取 (使用緩衝記憶體的快取) cache: 分頁快取 (使用kernel space記憶體去快取file的快取) avail: kernel space與user space的可以用的mem總和 ch6 cache mem 裡面就是一張表 name val is_dirty localty: time \u0026 space 讓proc同一時間使用的mem越少越好 transition lookaside buffer proc取值要 從fake addr換real addr 從real addr換值 (有cache的機會) 從fake addr換real addr是記憶體即便後面有cache主要的overhead還是吃在第一個 所以多一個buffer來把fake addr換成val 一些指令 /sys/system/cpu/cpu/cache/index type: data, code, unified shared_cpu_list size: total mem coherency_line_size: unit size page cache 把file讀到kernel的mem去cahce 所以在第一次之後的讀寫，不會每次都跑到HDD去(page in(HDD-\u003emem)/out(mem-\u003eHDD)沒有上升) 寫就會由kernel處理dirty的部分來做 一些指令 sar -d -p: HDD stat sat -B: page in/out sysctl vm.dirty_... echo 3 \u003e /proc/sys/vm/drop_cache: remove all cache hyper thread proc state的變化大概像 run(a) | sleep | run(c) | sleep 如果有多的reg的話可以在sleep時讓cpu當成一顆新的cpu去跑其他proc 所以，hyper thread就是保留一部份reg(一半)，把cpu當成兩顆用 ch7 file system 一定會有 name offset len 是不是很熟悉? 在exe info也有看過一樣的東西 其實就是把會記憶的東西當成一條常常的帶子(圖靈機) 但這樣不會有問題嗎? 特性 是一顆tree (從root開始) 有data與metadata 權限 file size timestamp quota user, folder, sub-disk(brtfs) inconsistent 從a的link改成b的link 加一條到b的link 把原本的a的link刪掉 (在這裡斷電) sol 日誌 在做事前先寫下步驟，在一步一步做 寫完步驟前出事 =\u003e old tree 做到一半出事 =\u003e redo, new tree copy-on-write (persistent data structrue) 每次的新增都是用新的位置 做到一半出事 =\u003e old tree fsck 找出inconsistent做處理 像在加一條到b的link出事會出現兩條link 這是可以選擇砍其中一條或是兩條都砍 device file type character 沒有seek，也就是沒有隨機讀取 可以寫字元與讀字元 用ps可以看到bash的/dev/pts/ 可以用echo \u003e /dev/pts/與# 一樣 block 可以當成記憶體 用mount 額外提一個mount --bind olddir newdir 這是把現有的folder連到另一個folder去，olddir的path依舊，但內容是newdir 可以用在olddir無法改變屬性時 strings -t -x可以把block dev的資料用string倒出來with addr 所以可以配合dd if=override_file of=/dev/sda1 seek=$(()) bs=1來改寫檔案內容 其他fs brtfs 大約等於 lvm+ext4 procfs /proc/ maps cmdline stat /proc cpuinfo, diskstat, meminfo /proc/sys/ sysctl sysfs /sys devices fs tmpfs, cgroupfs, nfs ch8 HDD 轉動很慢 IO scheduler: 在把req送到driver前 merge: 一次讀多一點 sort: 變成seq讀取 preread: 順便把其他的附近的也一起讀出來 SSD 隨著IO單位數的上升 throughput上升 IO scheduler的增益越來越不明顯，甚至損害效能 結論 一次讀多一點，資料量大沒關係 次數越少越好 在HDD與SSD，seq去讀寫的效能都是最好的，資料最好存在連續的區塊 ","wordCount":"454","inLanguage":"en","image":"https://littlebees.github.io/images/papermod-cover.png","datePublished":"2021-06-13T00:46:14Z","dateModified":"2021-06-13T00:46:14Z","author":{"@type":"Person","name":"zhengcf"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://littlebees.github.io/2021/06/%E5%9C%96%E8%A7%A3linux%E6%A0%B8%E5%BF%83%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%95%B4%E7%90%86/"},"publisher":{"@type":"Organization","name":"記事本","logo":{"@type":"ImageObject","url":"https://littlebees.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://littlebees.github.io/ accesskey=h title="記事本 (Alt + H)">記事本</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://littlebees.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://littlebees.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://littlebees.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://littlebees.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://littlebees.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">圖解linux核心工作原理整理</h1><div class=post-meta><span title='2021-06-13 00:46:14 +0000 UTC'>June 13, 2021</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;zhengcf</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e5%8b%95%e6%a9%9f aria-label=動機>動機</a></li><li><a href=#ch1 aria-label=ch1>ch1</a></li><li><a href=#ch2 aria-label=ch2>ch2</a></li><li><a href=#ch3 aria-label=ch3>ch3</a></li><li><a href=#ch4 aria-label=ch4>ch4</a></li><li><a href=#ch5 aria-label=ch5>ch5</a></li><li><a href=#ch6 aria-label=ch6>ch6</a></li><li><a href=#ch7 aria-label=ch7>ch7</a></li><li><a href=#ch8 aria-label=ch8>ch8</a></li></ul></div></details></div><div class=post-content><h2 id=動機>動機<a hidden class=anchor aria-hidden=true href=#動機>#</a></h2><p>都買了就讀一下</p><h2 id=ch1>ch1<a hidden class=anchor aria-hidden=true href=#ch1>#</a></h2><ul><li>cpu至少有兩種模式<ul><li>user mode</li><li>kernel mode: 可以access所有記憶體</li></ul></li></ul><h2 id=ch2>ch2<a hidden class=anchor aria-hidden=true href=#ch2>#</a></h2><ul><li>sys call<ul><li>目的: 讓user space的proc調用kernel space的功能，以操作或取得底層的資源<ul><li>用eval+apply的interp的角度去看，sys call就像primitive opertor</li><li>proc, mem, file, IPC, network, IO, time, &mldr;.</li><li>過程:<ul><li>塞sys call的編號到reg</li><li>發中斷(trap)</li><li>cpu切到kernel mode</li><li>請cpu跑sys call</li><li>cpu根據sys call的數字去看表</li><li>cpu跑kernel寫好的對應的handler</li><li>丟return 值，轉回去user mode</li></ul></li><li>一些指令<ul><li><code>sar -P ALL 1</code>: (mpstat) 可以看cpu的load<ul><li>user% + nice%: cpu是執行在user space的時間佔比<ul><li>user%: 就是一般的proc跑的</li><li>nice%: 有被調過nice有特權的proc所跑的時間</li></ul></li><li>sys%: cpu是執行在kernel space的時間佔比，也就是跑sys call的時間</li></ul></li><li><code>strace -T</code>: 顯示proc所執行的每個sys call與花了多少時間</li><li><code>ldd</code>: 看exe有link到哪些lib</li></ul></li></ul></li></ul></li></ul><h2 id=ch3>ch3<a hidden class=anchor aria-hidden=true href=#ch3>#</a></h2><ul><li>fork, execve: skip here</li><li>exe info<ul><li>exe的結構有三個部分<ul><li>info: 在linux是elf，會有很多資訊但對exe的結構來說重要的是<ul><li>每個部份的<ul><li>起點addr (fake addr)</li><li>長度</li><li>mapping後的起點addr (real addr)</li></ul></li><li>entry point</li></ul></li><li>code</li><li>data</li></ul></li><li>一些指令<ul><li><code>readelf -S</code>: 可以拿到起點addr與長度</li><li><code>cat /proc/&lt;pid>/maps</code>: 可以看proc的memory mapping</li></ul></li></ul></li></ul><h2 id=ch4>ch4<a hidden class=anchor aria-hidden=true href=#ch4>#</a></h2><ul><li>proc scheduler:<ul><li>round-robin<ul><li>1個cpu只會跑1個proc</li><li>每個proc都享有相同的時間去分cpu(沒nice的話)<ul><li>有nice的proc分到的cpu時間會比較多</li></ul></li></ul></li><li>在書中有一個程式是會fork多個proc(work load都一樣)去看分到的時間與執行狀況<ul><li>總執行時間隨fork出的proc變多而跟著上升</li><li>因為throughput不變，故隨著proc數上升，proc的latency(end_time-start_time)也會上升</li></ul></li><li>多cpu時會把proc往最少proc的cpu塞</li><li>一些指令<ul><li><code>tasklet -c &lt;cpuid> &lt;cmd></code>: 強制cmd跑在cpuid的cpu上</li><li><code>time ...</code><ul><li>proc state的變化大概像<ul><li><code>run(a) | sleep | run(c) | sleep</code></li></ul></li><li>real: end_time-start_time</li><li>user: user space</li><li>sys: kernel space<ul><li>user+sys就是把所有run時間加起來</li></ul></li></ul></li></ul></li></ul></li><li>proc state<ul><li>executing</li><li>waiting</li><li>sleeping<ul><li>D: wait IO</li><li>S: wait signal</li></ul></li><li>zombie</li></ul></li></ul><h2 id=ch5>ch5<a hidden class=anchor aria-hidden=true href=#ch5>#</a></h2><ul><li>virtual mem<ul><li>purpose:<ul><li>proc isolation<ul><li>C有ptr可以亂指，有virtual mem就指不出去</li><li>不過如果沒有ptr是不是就可以不用virtual mem?</li></ul></li><li>avoid mem fragment</li><li>support of multiple procs</li></ul></li><li>implement: page table<ul><li>可以當成一個存在於kernel的函數，all fake addr -> all real addr</li><li>demang page: lazy evaluation<ul><li>直到proc<strong>寫入</strong>時kernel才去找一個real addr</li><li>malloc是從先拿到的mem pool中拿addr，但mmap是sys call就是直接拿</li></ul></li><li>table太大了<ul><li>階層式page table<ul><li>從list變成tree，all fake addr -> (another table OR all real addr)</li></ul></li><li>huge page<ul><li>把page的單位變大，讓table的item數量變少</li></ul></li></ul></li></ul></li><li>file mapping: 把file複製到mem操作，最後在適當的時候把對file的改動寫回去</li><li>copy-on-write: 在fork時parent與child proc共用相同的Page，當其中一方改動時才複製新的，並把fake addr指到新的page上<ul><li>在算proc使用的mem時會各自顯示所以佔有的mem，但是因為copy-on-write實際上的mem使用量沒那麼多</li></ul></li><li>swap<ul><li>swap-in: mem -> swap(hdd)</li><li>swap-out: mem &lt;- swap(hdd)</li><li>持續 swap-in & swap-out: thrashing</li></ul></li><li>VSS & RSS<ul><li>fake mem usage & real mem usage</li><li>都有用完的機會，VSS是當table不夠時，RSS就是真的沒了</li></ul></li></ul></li><li>一些指令<ul><li><code>free</code><ul><li>total: 插了多少記憶體</li><li>buff: 緩衝快取 (使用緩衝記憶體的快取)</li><li>cache: 分頁快取 (使用kernel space記憶體去快取file的快取)</li><li>avail: kernel space與user space的可以用的mem總和</li></ul></li></ul></li></ul><h2 id=ch6>ch6<a hidden class=anchor aria-hidden=true href=#ch6>#</a></h2><ul><li>cache mem<ul><li>裡面就是一張表<ul><li>name</li><li>val</li><li>is_dirty</li></ul></li><li>localty: time & space<ul><li>讓proc同一時間使用的mem越少越好</li></ul></li><li>transition lookaside buffer<ul><li>proc取值要<ul><li>從fake addr換real addr</li><li>從real addr換值 (有cache的機會)</li></ul></li><li>從fake addr換real addr是記憶體即便後面有cache主要的overhead還是吃在第一個</li><li>所以多一個buffer來把fake addr換成val</li></ul></li><li>一些指令<ul><li><code>/sys/system/cpu/cpu&lt;i>/cache/index&lt;j></code><ul><li>type: data, code, unified</li><li>shared_cpu_list</li><li>size: total mem</li><li>coherency_line_size: unit size</li></ul></li></ul></li></ul></li><li>page cache<ul><li>把file讀到kernel的mem去cahce<ul><li>所以在第一次之後的讀寫，不會每次都跑到HDD去(page in(HDD->mem)/out(mem->HDD)沒有上升)</li><li>寫就會由kernel處理dirty的部分來做</li></ul></li><li>一些指令<ul><li><code>sar -d -p</code>: HDD stat</li><li><code>sat -B</code>: page in/out</li><li><code>sysctl vm.dirty_...</code></li><li><code>echo 3 > /proc/sys/vm/drop_cache</code>: remove all cache</li></ul></li></ul></li><li>hyper thread<ul><li>proc state的變化大概像<ul><li><code>run(a) | sleep | run(c) | sleep</code></li></ul></li><li>如果有多的reg的話可以在sleep時讓cpu當成一顆新的cpu去跑其他proc</li><li>所以，hyper thread就是保留一部份reg(一半)，把cpu當成兩顆用</li></ul></li></ul><h2 id=ch7>ch7<a hidden class=anchor aria-hidden=true href=#ch7>#</a></h2><ul><li>file system<ul><li>一定會有<ul><li>name</li><li>offset</li><li>len<ul><li>是不是很熟悉?</li><li>在exe info也有看過一樣的東西</li><li>其實就是把會記憶的東西當成一條常常的帶子(圖靈機)</li><li>但這樣不會有問題嗎?</li></ul></li></ul></li><li>特性<ul><li>是一顆tree (從root開始)</li><li>有data與metadata<ul><li>權限</li><li>file size</li><li>timestamp</li></ul></li><li>quota<ul><li>user, folder, sub-disk(brtfs)</li></ul></li></ul></li><li>inconsistent<ul><li>從a的link改成b的link<ul><li>加一條到b的link</li><li>把原本的a的link刪掉 (在這裡斷電)</li></ul></li><li>sol<ul><li>日誌<ul><li>在做事前先寫下步驟，在一步一步做<ul><li>寫完步驟前出事 => old tree</li><li>做到一半出事 => redo, new tree</li></ul></li></ul></li><li>copy-on-write (persistent data structrue)<ul><li>每次的新增都是用新的位置<ul><li>做到一半出事 => old tree</li></ul></li></ul></li><li>fsck<ul><li>找出inconsistent做處理<ul><li>像在<strong>加一條到b的link</strong>出事會出現兩條link</li><li>這是可以選擇砍其中一條或是<strong>兩條都砍</strong></li></ul></li></ul></li></ul></li></ul></li></ul></li><li>device file<ul><li>type<ul><li>character<ul><li>沒有seek，也就是沒有隨機讀取</li><li>可以寫字元與讀字元</li><li>用<code>ps</code>可以看到bash的<code>/dev/pts/&lt;n></code><ul><li>可以用<code>echo &lt;cmd> > /dev/pts/&lt;n></code>與<code># &lt;cmd></code>一樣</li></ul></li></ul></li><li>block<ul><li>可以當成記憶體</li><li>用<code>mount</code><ul><li>額外提一個<code>mount --bind olddir newdir</code></li><li>這是把現有的folder連到另一個folder去，olddir的path依舊，但內容是newdir</li><li>可以用在olddir無法改變屬性時</li></ul></li><li><code>strings -t -x</code>可以把block dev的資料用string倒出來with addr<ul><li>所以可以配合<code>dd if=override_file of=/dev/sda1 seek=$((&lt;addr>)) bs=1</code>來改寫檔案內容</li></ul></li></ul></li></ul></li></ul></li><li>其他fs<ul><li>brtfs 大約等於 lvm+ext4</li><li>procfs<ul><li><code>/proc/&lt;pid></code><ul><li>maps</li><li>cmdline</li><li>stat</li></ul></li><li><code>/proc</code><ul><li>cpuinfo, diskstat, meminfo</li></ul></li><li><code>/proc/sys/</code><ul><li>sysctl</li></ul></li></ul></li><li>sysfs<ul><li><code>/sys</code><ul><li>devices</li><li>fs</li></ul></li></ul></li><li>tmpfs, cgroupfs, nfs</li></ul></li></ul><h2 id=ch8>ch8<a hidden class=anchor aria-hidden=true href=#ch8>#</a></h2><ul><li>HDD<ul><li>轉動很慢<ul><li>IO scheduler: 在把req送到driver前<ul><li>merge: 一次讀多一點</li><li>sort: 變成seq讀取</li></ul></li><li>preread: 順便把其他的附近的也一起讀出來</li></ul></li></ul></li><li>SSD<ul><li>隨著IO單位數的上升<ul><li>throughput上升</li><li>IO scheduler的增益越來越不明顯，甚至損害效能</li></ul></li></ul></li><li>結論<ul><li>一次讀多一點，資料量大沒關係</li><li>次數越少越好</li><li>在HDD與SSD，seq去讀寫的效能都是最好的，資料最好存在連續的區塊</li></ul></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://littlebees.github.io/tags/linux/>Linux</a></li></ul><nav class=paginav><a class=prev href=https://littlebees.github.io/2021/06/keepassxc%E5%90%8C%E6%AD%A5db%E8%88%87%E8%87%AA%E5%8B%95%E9%96%8Bdb/><span class=title>« Prev</span><br><span>keepassxc同步db與自動開db</span>
</a><a class=next href=https://littlebees.github.io/2021/06/%E6%94%B9manga-loader%E7%9A%84%E5%BF%83%E5%BE%97%E8%88%87%E4%B8%80%E4%BA%9B%E6%96%B9%E6%B3%95/><span class=title>Next »</span><br><span>改Manga-Loader的心得與一些方法</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://littlebees.github.io/>記事本</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>