<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>the complete guide to rails performance讀後筆記 | 記事本</title>
<meta name=keywords content="Rails"><meta name=description content="動機
好看的書，但我主要是看怎麼profile與gc所以有跳過一些部分
跳過:
webfont, CDN, SSL, HTTP cache, Rails Cache, Backgrounding Work"><meta name=author content="zhengcf"><link rel=canonical href=https://littlebees.github.io/2022/01/the-complete-guide-to-rails-performance%E8%AE%80%E5%BE%8C%E7%AD%86%E8%A8%98/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://littlebees.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://littlebees.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://littlebees.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://littlebees.github.io/apple-touch-icon.png><link rel=mask-icon href=https://littlebees.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://littlebees.github.io/2022/01/the-complete-guide-to-rails-performance%E8%AE%80%E5%BE%8C%E7%AD%86%E8%A8%98/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="the complete guide to rails performance讀後筆記"><meta property="og:description" content="動機
好看的書，但我主要是看怎麼profile與gc所以有跳過一些部分
跳過:
webfont, CDN, SSL, HTTP cache, Rails Cache, Backgrounding Work"><meta property="og:type" content="article"><meta property="og:url" content="https://littlebees.github.io/2022/01/the-complete-guide-to-rails-performance%E8%AE%80%E5%BE%8C%E7%AD%86%E8%A8%98/"><meta property="og:image" content="https://littlebees.github.io/images/papermod-cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-01-30T14:44:01+00:00"><meta property="article:modified_time" content="2022-01-30T14:44:01+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://littlebees.github.io/images/papermod-cover.png"><meta name=twitter:title content="the complete guide to rails performance讀後筆記"><meta name=twitter:description content="動機
好看的書，但我主要是看怎麼profile與gc所以有跳過一些部分
跳過:
webfont, CDN, SSL, HTTP cache, Rails Cache, Backgrounding Work"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://littlebees.github.io/posts/"},{"@type":"ListItem","position":2,"name":"the complete guide to rails performance讀後筆記","item":"https://littlebees.github.io/2022/01/the-complete-guide-to-rails-performance%E8%AE%80%E5%BE%8C%E7%AD%86%E8%A8%98/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"the complete guide to rails performance讀後筆記","name":"the complete guide to rails performance讀後筆記","description":"動機 好看的書，但我主要是看怎麼profile與gc所以有跳過一些部分\n跳過: webfont, CDN, SSL, HTTP cache, Rails Cache, Backgrounding Work\n","keywords":["Rails"],"articleBody":"動機 好看的書，但我主要是看怎麼profile與gc所以有跳過一些部分\n跳過: webfont, CDN, SSL, HTTP cache, Rails Cache, Backgrounding Work\nprinciple Benford’s Law 越大的數，以它為首幾位的數出現的機率就越低。它可用於檢查各種數據是否有造假 Zipf’s law 一個單詞出現的頻率與它在頻率表里的排名成反比 只有少數的單字常常被使用 Zipf’s law是離散的分布，如果用成連續的就是Pareto’s law(80/20)\nPareto’s law 80%的財富掌握在20%的人手上 Pareto’s law告訴我們把時間花在找出那20%決定80%的部分\n所以下面的章節有很大一部分在怎麼測量，與測量什麼\nlittle law $l=\\lambda w$ $l$是幾台主機 $\\lambda$是單位時間有多少req $w$是主機的avg. response time\n這是針對長期而言的式子，主要是用來看有沒有over-scaled(太多主機了、太少主機了(主機數剛好是算出來的數字!?)) 另外，little law預設，req彼此獨立、server彼此獨立(不能互卡(IO)、卡資源(cpu或mem有限))、response不能差平均太多(95th percentile response times很重要)\n同時也是說，scale對avg. response time沒有影響，對\nthroughput有影響 減少user在queue中的等待時間有影響 如果在queue中平均等待的人數少於1，或是在queue中等待的時間太短 scale的效果就不明顯 server沒有全力工作(100%) 所以要在到達這個點之前先scale 如果avg. response time慢，更應該如此 但要注意邊際遞減 (Amdahl’s law) The Performance Workflow 有沒有metrics怪怪的 profile找兇手，在哪邊花了最多時間 做小範圍的benchmark，測時間或是花費資源 develop環境的benchmark結果會與production的有差距 例: 500ms in production vs 1000ms locally Generally a factor of 3 is acceptable profile的結果不一定準 如果把佔了50%的method拿掉，不一定讓結果變好50% 做整體的benchmark與profile，確定改的是對的 profile profile: 測code各個部位的資源占比\nprofile mode mode不同讓測出來的時間不一樣\nCPU - clock counter 數clock cycles “Amount of clock cycles” / “CPU frequency” 但現在cpu會stepping load重的時候把clock frequency調高 system-wide 改用time stamp counter去算時間 這樣其他工作也會影響到當前的profile 建議 Use CPU time when you’re interested in seeing the profile without I/O Wall time 就是看start之後扣掉end wall就是牆上的時間 影響到當前的profile 其他process使用相同的資源 Network or I/O 建議 Despite its flaws, wall time is usually the mode you’ll want to use Process time 只測量目前process花的時間 不包括forked的process 建議 process time, if available, is usually a better choice over CPU time. If you have code that spawns subprocesses, you may need to stick with CPU time (or wall time). 有的profiler把cpu time當成這裡的process time 還有測量方式，profiler都是看在stack上花的時間去算占比\nTracing 每個invoke都記錄 超準 超浪費資源 Sampling 一定時間固定去看stack的樣子，紀錄占比 要抽樣夠多次才準 因為資源占比小，所以可以放在prodution環境中看profile ruby: Ruby-Prof Ruby-Prof直接與MRI掛勾(tracing)，所以一但跑了就會比平常慢2到3倍\nrequire 'ruby-prof' SORTED_ARRAY = Array.new(10_000) { rand(100_000) }.sort! array_size = SORTED_ARRAY.size RubyProf.measure_mode = RubyProf::CPU_TIME result = RubyProf.profile do 1_000_000.times { bsearch2(SORTED_ARRAY, rand(array_size)) } end printer = RubyProf::FlatPrinter.new(result) printer.print(STDOUT) %self total self wait child calls name 17.22 19.117 12.777 0.000 6.340 13182869 Fixnum#== 8.54 6.340 6.340 0.000 0.000 13182869 BasicObject#== 5.73 71.918 4.252 0.000 67.666 14182869 *Object#bsearch2 2.14 74.196 1.590 0.000 72.606 1 Integer#times 0.93 0.688 0.688 0.000 0.000 1000000 Kernel#rand 0.68 0.508 0.508 0.000 0.000 1000000 Array#count 0.00 74.196 0.000 0.000 74.196 1 Global#[No method] %self: 花在這個method的時間占比 total: 這個method與child共花了多少時間 self: 這個method花了多少時間 child: total - self calls: 被call了幾次\n從%self的下手!!\nruby: Stackprof 做sampling的profiler是rack-mini-profiler的backend\n一般不會在開發時使用，因為Ruby-Prof比較準\nrack: rack-mini-profiler 除了一般的profile還可以看\nSQL query server response time method的flamegraph memory leak(gc) 同時rack-mini-profiler本來就是設計給production用的!!\n記得，如果在profile速度時，要調到prodution mode，因為development mode會有需多方便開發的功能把速度拖慢\n裝完就可以啟動網站，之後網頁會出現一個badge裡面大概像 之後就可以問\nHow many SQL queries am I generating? 一般來說一個orm的class就只會有一條SQL 一個簡單page一般來說是1~3條SQL What’s my total request time? 一般會希望在50ms以下 What % of time am I spending in SQL? 最好使用production的DB去測 通常production的資料量遠比develop大 How long until DOMContentLoaded fires? 從收到response到出現在畫面上需要一段過程 這留到前端優化 Are any of the parts of the page taking up an extreme amount of time compared to others? 往有SQL的項目點，可以看partial render時間與SQL時間，與花在這個項目的時間(左邊) 那中間差的時間呢? 就是在code上的，詳細的需要看flamegraph\n通常遇到partial的SQL可以試著\n把整個拿掉 cache partial 善用includes一次多load一點 另外還有profile-gc、profile-memory可以看記憶體與gc的情況!! profile-gc就是GC.stat，可以看\nNew bytes allocated outside of Ruby heaps 過了10MB要特別注意 ObjectSpace delta caused by request 收到req之後多了多少物件與哪種物件 rack-mini-profiler利用profile-memory去看\nallocated memory by gem allocated memory by file allocated objects by gem memory profile 因為多了vm這一層，所以memory profile變得很麻煩 下面的工具都是基於MRI的\nObjectSpace and objspace.so ObjectSpace就是所有object的存放地，因為是與MRI深度綁定，所以不要在prodution用\n下面來看看有什麼有趣的功能\n像ObjectSpace.count_objects\nirb(main):001:0\u003e ObjectSpace.count_objects =\u003e {:TOTAL=\u003e53802, :FREE=\u003e31, :T_OBJECT=\u003e3373, :T_CLASS=\u003e888, :T_MODULE=\u003e30, :T_FLOAT=\u003e4, :T_STRING=\u003e36497, :T_REGEXP=\u003e164, :T_ARRAY=\u003e9399, :T_HASH=\u003e789, :T_STRUCT=\u003e2, :T_BIGNUM=\u003e2, :T_FILE=\u003e7, :T_DATA=\u003e1443, :T_MATCH=\u003e85, :T_COMPLEX=\u003e1, :T_NODE=\u003e1050, :T_ICLASS=\u003e37} 好懂的好懂，但還是有些怪怪的\nT_NODE: AST T_DATA: interrupter自己的東西 這裡就看我們知道的基本type就好\n利用這個與gc開關可以來寫個簡單的benchmark看一段code產生多少object\ndef allocate_count GC.disable before = ObjectSpace.count_objects yield after = ObjectSpace.count_objects after.each { |k,v| after[k] = v - before[k] } after[:T_HASH] -= 1 # probe effect - we created the before hash. after[:FREE] += 1 # same GC.enable after.reject { |k,v| v == 0 } end allocate_count { 100.times { 'hello' + 'hi' }} 同時也可以看現在有多少存活的object\nputs ObjectSpace.each_object.count puts ObjectSpace.each_object(Numeric).count puts ObjectSpace.each_object(Complex).count ObjectSpace.each_object(Complex) { |c| puts c 看一個type總共花的多少mem\nirb(main):057:0\u003e ObjectSpace.count_objects_size { :T_OBJECT =\u003e 198560, :T_CLASS =\u003e 614784, :T_MODULE =\u003e 66712, :T_FLOAT =\u003e 160, :T_STRING =\u003e 1578522, :T_REGEXP =\u003e 122875, :T_ARRAY =\u003e 630976, :T_HASH =\u003e 165672, :T_STRUCT =\u003e 160 ... 看看這個物件佔了多少mem\nirb(main):062:0\u003e ObjectSpace.memsize_of(\"The quick brown fox jumps over the lazy dog\") 40 # NOT ACCURATE irb(main):063:0\u003e ObjectSpace.memsize_of(\"The quick brown fox\") 40 irb(main):064:0\u003e ObjectSpace.memsize_of([]) 40 irb(main):065:0\u003eObjectSpace.memsize_of(Array.new(10_000) { :a }) 80040 為什麼是40? ruby vm的RVALUE大小就是40bytes\n使用時機:\n各種try，以增加gc的知識 用 ObjectSpace.each_object 去check live objects 如果市面上的profiler不行了，可以hack這個來做profile GC::Profiler ruby的gc是generational garbage collector\n看object活過幾次GC來對object分類 活過一次就是old 可以看old_objects(GC.stat)找有沒有memory leak發生 如果這個值慢慢上升就是中了 Minor GCs 只挑new處理 核心思想是 通常object沒有幾個會活很久 GC.count就是從執行程式以來GC被執行的總次數，包含major與minor GC.stat就是各種參數，除了GC的還有memory本身的各種數值\n跑跑GC::profiler吧\nGC::Profiler.enable require 'set' GC.start GC::Profiler.report GC::Profiler.disable GC 133 invokes. Index Invoke Time(sec) Use Size(byte) Total Size(byte) Total Object GC Time(ms) 1 1.966 801240 6315840 157896 2.33700000000003349498 invoke的值與GC.count一樣也就是，這是從執行程式以來GC被執行的總次數\n使用時機: 如果gc跑太久，GC與GC::Profiler是個很好的開始\nderailed_benchmarks 這個是看memory用量，可以追memory bloat\n像bundle exec derailed bundle:mem 會列出每個gem用多少memory\ndelayed_job: 18.9805 MiB (Also required by: delayed/railtie, delayed_job_active_record) delayed/performable_mailer: 17.8633 MiB mail: 17.8555 MiB (Also required by: TOP) mime/types: 12.9492 MiB (Also required by: /Users/nateberkopec/.gem/ruby/2.3.0/gems/rest-client\u00021.8.0/lib/restclient/request, /Users/nateberkopec/.gem/ruby/2.3.0/gems/rest-client\u00021.8.0/lib/restclient/payload) mail/field: 2.0039 MiB mail/message: 0.8477 MiB delayed/worker: 0.6055 MiB rails/all: 15.8125 MiB rails: 7.5352 MiB (Also required by: active_record/railtie, active_model/railtie, and 10 others) rails/application: 5.3867 MiB [… continues on and on] 跑app多次，看最後花了多少mem derailed exec perf:mem_over_time 如果持續上升，memory leak\n看object到底在哪產生的 derailed exec perf:objects 可以用來追哪個指令用memory太兇\n使用時機:\nbundle:mem來check gem的mem占量，與減少mem bloat trace mem leak memory_profiler memory_profiler其實是derailed_benchmarks的backend\nmemory_profiler可以只對一段code做profile\nrequire 'memory_profiler' report = MemoryProfiler.report do # run your code here end report.pretty_print 之後的report會有\nRetained memory 在跑profiler之前就在的object Allocated memory 跑profiler時alloc的object 高Allocated memory代表gc會跑比較多次，程式會變慢 另外，memory_profiler跑出來的usage與會比ps看到的少，因為ruby有memory fragmentation\nmemory_profiler也可以profile c extendsion的memory\n使用時機\n要追non-Rack-app與background jobs的mem issue Rack的app可以用 derailed and rack-mini-profiler front-end: chrome timeline 對於end-user而言，Server response times(100ms~300ms)不是重點，因為占比很小(10%) 整個load time大概是1~3秒\ngzipped size對於花多久時間下載很重要\nunzip 後的size對花多久時間parse與construct很重要\nNew Relic的real user monitoring (RUM)可以提供大概end-user感覺的page load time\nChrome Timeline可以看到每一步的實際狀況\nChrome Timeline同時會記錄其他extensions的事件!! (記得關其他extendsion) 整個流程 (從browser的角度)\nDNS/TCP/SSL setup download html parsing html. 一但遇到其他資源就停下parse等載好跑完才會繼續parse css不會擋parse js上async或是defer不會擋parse 剛剛提到不會被擋的東西，preloader會在他簡單掃過後去preload!! 所以我們要\nDon’t stop the parser. preloader會在parser跑之前先掃看有沒有可以先下載的東西 head, script, … 如果用js做動態生dom(script)，這樣preloader看不到!! Get out of the browser preloader’s way. preloader不吃 iframe webfont HTML5 audio/video css @import Use HTTP caching - but not too much. 把常用的設成cache，自己打包(jquery…) 如果賭user有大廠的api(來自google的cdn之類) 有，沒事 沒有，整個parse被block!! Use the Resource Hint API. DNS Prefetch Preconnect Prefetch Prerender 整個流程 (從網頁的角度)\n送request，等response 這不會出現在timeline上，前面的空白就是這段時間 包含 service response time (大約10ms) network latency (大約10ms~300ms，看有沒有跨境) 光速從新加坡到US都要花70ms!! Receive Response 在收到任何byte就會有這一事件 這就是下載，完成下載後會有Finish Loading 所以後面會看到很多這個event Parse HTML 把html轉成dom 下載需要的resource ","wordCount":"2604","inLanguage":"en","image":"https://littlebees.github.io/images/papermod-cover.png","datePublished":"2022-01-30T14:44:01Z","dateModified":"2022-01-30T14:44:01Z","author":{"@type":"Person","name":"zhengcf"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://littlebees.github.io/2022/01/the-complete-guide-to-rails-performance%E8%AE%80%E5%BE%8C%E7%AD%86%E8%A8%98/"},"publisher":{"@type":"Organization","name":"記事本","logo":{"@type":"ImageObject","url":"https://littlebees.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://littlebees.github.io/ accesskey=h title="記事本 (Alt + H)">記事本</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://littlebees.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://littlebees.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://littlebees.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://littlebees.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://littlebees.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">the complete guide to rails performance讀後筆記</h1><div class=post-meta><span title='2022-01-30 14:44:01 +0000 UTC'>January 30, 2022</span>&nbsp;·&nbsp;13 min&nbsp;·&nbsp;zhengcf</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e5%8b%95%e6%a9%9f aria-label=動機>動機</a></li><li><a href=#principle aria-label=principle>principle</a><ul><li><a href=#benfords-law aria-label="Benford’s Law">Benford’s Law</a></li><li><a href=#zipfs-law aria-label="Zipf&rsquo;s law">Zipf&rsquo;s law</a></li><li><a href=#paretos-law aria-label="Pareto&rsquo;s law">Pareto&rsquo;s law</a></li><li><a href=#little-law aria-label="little law">little law</a></li></ul></li><li><a href=#the-performance-workflow aria-label="The Performance Workflow">The Performance Workflow</a></li><li><a href=#profile aria-label=profile>profile</a><ul><li><a href=#profile-mode aria-label="profile mode">profile mode</a></li><li><a href=#ruby-ruby-prof aria-label="ruby: Ruby-Prof">ruby: Ruby-Prof</a></li><li><a href=#ruby-stackprof aria-label="ruby: Stackprof">ruby: Stackprof</a></li><li><a href=#rack-rack-mini-profiler aria-label="rack: rack-mini-profiler">rack: rack-mini-profiler</a></li><li><a href=#memory-profile aria-label="memory profile">memory profile</a><ul><li><a href=#objectspace-and-objspaceso aria-label="ObjectSpace and objspace.so">ObjectSpace and objspace.so</a></li><li><a href=#gcprofiler aria-label=GC::Profiler>GC::Profiler</a></li><li><a href=#derailed_benchmarks aria-label=derailed_benchmarks>derailed_benchmarks</a></li><li><a href=#memory_profiler aria-label=memory_profiler>memory_profiler</a></li></ul></li><li><a href=#front-end-chrome-timeline aria-label="front-end: chrome timeline">front-end: chrome timeline</a></li><li><a href=#3rd-party-new-relic aria-label="3rd-party: New Relic">3rd-party: New Relic</a><ul><li><a href=#development--production-%e7%92%b0%e5%a2%83%e6%9c%83%e6%9c%89%e5%b7%ae%e7%95%b0%e7%9a%84%e5%8e%9f%e5%9b%a0 aria-label="development & production 環境會有差異的原因">development & production 環境會有差異的原因</a></li><li><a href=#new-relic-profile-in-production-env aria-label="New Relic: profile in production env">New Relic: profile in production env</a></li><li><a href=#process-time aria-label="process time">process time</a></li><li><a href=#transactions aria-label=Transactions>Transactions</a></li><li><a href=#database aria-label=database>database</a></li><li><a href=#external-services aria-label="External Services">External Services</a></li><li><a href=#gc-stats-and-reports aria-label="GC stats and Reports">GC stats and Reports</a></li><li><a href=#browser--real-user-monitoring-rum aria-label="Browser / Real user monitoring (RUM)">Browser / Real user monitoring (RUM)</a></li></ul></li></ul></li><li><a href=#turbolinks--html-over-the-wire aria-label="Turbolinks & &ldquo;HTML-over-the-wire&rdquo;">Turbolinks & &ldquo;HTML-over-the-wire&rdquo;</a></li><li><a href=#%e9%97%9c%e6%96%bc%e5%8f%8d%e6%87%89%e6%99%82%e9%96%93 aria-label=關於反應時間>關於反應時間</a></li><li><a href=#benchmark aria-label=benchmark>benchmark</a></li><li><a href=#performance%e4%b9%8b%e6%96%bc%e4%bc%81%e6%a5%ad aria-label=performance之於企業>performance之於企業</a></li><li><a href=#db-optimization aria-label="DB optimization">DB optimization</a></li><li><a href=#rails-slow aria-label="Rails slow?">Rails slow?</a></li><li><a href=#exception-slow aria-label="exception slow!!">exception slow!!</a></li><li><a href=#memory-bloat aria-label="memory bloat">memory bloat</a></li><li><a href=#memory-leaks aria-label="Memory Leaks">Memory Leaks</a></li><li><a href=#memory-fragmentation aria-label="Memory Fragmentation">Memory Fragmentation</a></li><li><a href=#%e9%97%9c%e6%96%bcapplication-server%e6%9c%ac%e8%ba%ab aria-label="關於application server本身">關於application server本身</a><ul><li><a href=#the-life-of-a-request aria-label="The life of a request">The life of a request</a></li><li><a href=#server%e5%9c%a8scale%e4%b8%8a%e5%b7%ae%e5%9c%a8 aria-label=server在scale上差在?>server在scale上差在?</a><ul><li><a href=#%e8%a8%ad%e5%ae%9aserver%e5%8f%83%e6%95%b8 aria-label=設定server參數>設定server參數</a></li></ul></li></ul></li><li><a href=#gc aria-label=gc>gc</a></li><li><a href=#orm aria-label=orm>orm</a></li></ul></div></details></div><div class=post-content><h2 id=動機>動機<a hidden class=anchor aria-hidden=true href=#動機>#</a></h2><p>好看的書，但我主要是看怎麼profile與gc所以有跳過一些部分</p><p>跳過:
webfont, CDN, SSL, HTTP cache, Rails Cache, Backgrounding Work</p><h2 id=principle>principle<a hidden class=anchor aria-hidden=true href=#principle>#</a></h2><h3 id=benfords-law>Benford’s Law<a hidden class=anchor aria-hidden=true href=#benfords-law>#</a></h3><p>越大的數，以它為首幾位的數出現的機率就越低。它可用於檢查各種數據是否有造假
<img loading=lazy src=https://i.imgur.com/uUmuAAc.png alt></p><h3 id=zipfs-law>Zipf&rsquo;s law<a hidden class=anchor aria-hidden=true href=#zipfs-law>#</a></h3><p>一個單詞出現的頻率與它在頻率表里的排名成反比
只有少數的單字常常被使用
<img loading=lazy src=https://i.imgur.com/x2jHpeF.png alt></p><p>Zipf&rsquo;s law是離散的分布，如果用成連續的就是Pareto&rsquo;s law(80/20)</p><h3 id=paretos-law>Pareto&rsquo;s law<a hidden class=anchor aria-hidden=true href=#paretos-law>#</a></h3><p>80%的財富掌握在20%的人手上
<img loading=lazy src=https://i.imgur.com/kxq0WSa.png alt></p><p>Pareto&rsquo;s law告訴我們把時間花在找出那20%決定80%的部分</p><p>所以下面的章節有很大一部分在怎麼測量，與測量什麼</p><h3 id=little-law>little law<a hidden class=anchor aria-hidden=true href=#little-law>#</a></h3><p>$l=\lambda w$
$l$是幾台主機
$\lambda$是單位時間有多少req
$w$是主機的avg. response time</p><p>這是針對長期而言的式子，主要是用來看有沒有over-scaled(太多主機了、太少主機了(主機數剛好是算出來的數字!?))
另外，little law預設，req彼此獨立、server彼此獨立(不能互卡(IO)、卡資源(cpu或mem有限))、response不能差平均太多(95th percentile response times很重要)</p><p>同時也是說，scale對avg. response time沒有影響，對</p><ul><li>throughput有影響</li><li>減少user在queue中的等待時間有影響<ul><li>如果在queue中平均等待的人數少於1，或是在queue中等待的時間太短<ul><li>scale的效果就不明顯</li><li>server沒有全力工作(100%)</li></ul></li><li>所以要在到達這個點之前先scale<ul><li>如果avg. response time慢，更應該如此<ul><li>但要注意邊際遞減 (Amdahl&rsquo;s law)</li></ul></li></ul></li></ul></li></ul><h2 id=the-performance-workflow>The Performance Workflow<a hidden class=anchor aria-hidden=true href=#the-performance-workflow>#</a></h2><ol><li>有沒有metrics怪怪的</li><li>profile找兇手，在哪邊花了最多時間</li><li>做小範圍的benchmark，測時間或是花費資源<ul><li>develop環境的benchmark結果會與production的有差距<ul><li>例: 500ms in production vs 1000ms locally<ul><li>Generally a factor of 3 is acceptable</li></ul></li></ul></li><li>profile的結果不一定準<ul><li>如果把佔了50%的method拿掉，不一定讓結果變好50%</li></ul></li></ul></li><li>做整體的benchmark與profile，確定改的是對的</li></ol><h2 id=profile>profile<a hidden class=anchor aria-hidden=true href=#profile>#</a></h2><p>profile: 測code各個部位的資源占比</p><h3 id=profile-mode>profile mode<a hidden class=anchor aria-hidden=true href=#profile-mode>#</a></h3><p>mode不同讓測出來的時間不一樣</p><ul><li>CPU - clock counter<ul><li>數clock cycles<ul><li>“Amount of clock cycles” / “CPU frequency”</li><li>但現在cpu會stepping<ul><li>load重的時候把clock frequency調高</li></ul></li></ul></li><li>system-wide<ul><li>改用time stamp counter去算時間</li><li>這樣其他工作也會影響到當前的profile</li></ul></li><li>建議<ul><li>Use CPU time when you’re interested in seeing the profile without I/O</li></ul></li></ul></li><li>Wall time<ul><li>就是看start之後扣掉end<ul><li>wall就是牆上的時間</li></ul></li><li>影響到當前的profile<ul><li>其他process使用相同的資源</li><li>Network or I/O</li></ul></li><li>建議<ul><li>Despite its flaws, wall time is usually the mode you’ll want to use</li></ul></li></ul></li><li>Process time<ul><li>只測量目前process花的時間<ul><li>不包括forked的process</li></ul></li><li>建議<ul><li>process time, if available, is usually a better choice over CPU time.</li><li>If you have code that spawns subprocesses, you may need to stick with CPU time (or wall time).</li></ul></li><li>有的profiler把cpu time當成這裡的process time</li></ul></li></ul><p>還有測量方式，profiler都是看在stack上花的時間去算占比</p><ul><li>Tracing<ul><li>每個invoke都記錄<ul><li>超準</li><li>超浪費資源</li></ul></li></ul></li><li>Sampling<ul><li>一定時間固定去看stack的樣子，紀錄占比<ul><li>要抽樣夠多次才準</li></ul></li><li>因為資源占比小，所以可以放在prodution環境中看profile</li></ul></li></ul><h3 id=ruby-ruby-prof>ruby: Ruby-Prof<a hidden class=anchor aria-hidden=true href=#ruby-ruby-prof>#</a></h3><p>Ruby-Prof直接與MRI掛勾(tracing)，所以一但跑了就會比平常慢2到3倍</p><pre tabindex=0><code class="language-ruby=" data-lang="ruby=">require &#39;ruby-prof&#39;
SORTED_ARRAY = Array.new(10_000) { rand(100_000) }.sort!
array_size = SORTED_ARRAY.size
RubyProf.measure_mode = RubyProf::CPU_TIME
result = RubyProf.profile do
    1_000_000.times { bsearch2(SORTED_ARRAY, rand(array_size)) }
end
printer = RubyProf::FlatPrinter.new(result)
printer.print(STDOUT)
</code></pre><pre tabindex=0><code>%self total self wait child calls name
17.22 19.117 12.777 0.000 6.340 13182869 Fixnum#==
8.54 6.340 6.340 0.000 0.000 13182869 BasicObject#==
5.73 71.918 4.252 0.000 67.666 14182869 *Object#bsearch2
2.14 74.196 1.590 0.000 72.606 1 Integer#times
0.93 0.688 0.688 0.000 0.000 1000000 Kernel#rand
0.68 0.508 0.508 0.000 0.000 1000000 Array#count
0.00 74.196 0.000 0.000 74.196 1 Global#[No method]
</code></pre><p><code>%self</code>: 花在這個method的時間占比
<code>total</code>: 這個method與child共花了多少時間
<code>self</code>: 這個method花了多少時間
<code>child</code>: <code>total</code> - <code>self</code>
<code>calls</code>: 被call了幾次</p><p>從<code>%self</code>的下手!!</p><h3 id=ruby-stackprof>ruby: Stackprof<a hidden class=anchor aria-hidden=true href=#ruby-stackprof>#</a></h3><p>做sampling的profiler是rack-mini-profiler的backend</p><p>一般不會在開發時使用，因為Ruby-Prof比較準</p><h3 id=rack-rack-mini-profiler>rack: rack-mini-profiler<a hidden class=anchor aria-hidden=true href=#rack-rack-mini-profiler>#</a></h3><p>除了一般的profile還可以看</p><ul><li>SQL query</li><li>server response time</li><li>method的flamegraph</li><li>memory leak(gc)</li></ul><p>同時rack-mini-profiler本來就是設計給production用的!!</p><p>記得，如果在profile速度時，要調到prodution mode，因為development mode會有需多方便開發的功能把速度拖慢</p><p>裝完就可以啟動網站，之後網頁會出現一個badge裡面大概像
<img loading=lazy src=https://i.imgur.com/Ad8QDG1.png alt></p><p>之後就可以問</p><ul><li>How many SQL queries am I generating?<ul><li>一般來說一個orm的class就只會有一條SQL</li><li>一個簡單page一般來說是1~3條SQL</li></ul></li><li>What’s my total request time?<ul><li>一般會希望在50ms以下</li></ul></li><li>What % of time am I spending in SQL?<ul><li>最好使用production的DB去測<ul><li>通常production的資料量遠比develop大</li></ul></li></ul></li><li>How long until DOMContentLoaded fires?<ul><li>從收到response到出現在畫面上需要一段過程<ul><li>這留到前端優化</li></ul></li></ul></li><li>Are any of the parts of the page taking up an extreme amount of time compared to others?</li></ul><p>往有SQL的項目點，可以看partial render時間與SQL時間，與花在這個項目的時間(左邊)
<img loading=lazy src=https://i.imgur.com/eGRXTwR.png alt></p><p>那中間差的時間呢?
就是在code上的，詳細的需要看flamegraph</p><p>通常遇到partial的SQL可以試著</p><ul><li>把整個拿掉</li><li>cache partial</li><li>善用includes一次多load一點</li></ul><p>另外還有profile-gc、profile-memory可以看記憶體與gc的情況!!
profile-gc就是GC.stat，可以看</p><ul><li>New bytes allocated outside of Ruby heaps<ul><li>過了10MB要特別注意</li></ul></li><li>ObjectSpace delta caused by request<ul><li>收到req之後多了多少物件與哪種物件</li></ul></li></ul><p>rack-mini-profiler利用profile-memory去看</p><ul><li>allocated memory by gem</li><li>allocated memory by file</li><li>allocated objects by gem</li></ul><h3 id=memory-profile>memory profile<a hidden class=anchor aria-hidden=true href=#memory-profile>#</a></h3><p>因為多了vm這一層，所以memory profile變得很麻煩
下面的工具都是基於MRI的</p><h4 id=objectspace-and-objspaceso>ObjectSpace and objspace.so<a hidden class=anchor aria-hidden=true href=#objectspace-and-objspaceso>#</a></h4><p>ObjectSpace就是所有object的存放地，因為是與MRI深度綁定，所以不要在prodution用</p><p>下面來看看有什麼有趣的功能</p><p>像ObjectSpace.count_objects</p><pre tabindex=0><code>irb(main):001:0&gt; ObjectSpace.count_objects
=&gt; {:TOTAL=&gt;53802, :FREE=&gt;31, :T_OBJECT=&gt;3373,
:T_CLASS=&gt;888, :T_MODULE=&gt;30, :T_FLOAT=&gt;4,
:T_STRING=&gt;36497, :T_REGEXP=&gt;164, :T_ARRAY=&gt;9399,
:T_HASH=&gt;789, :T_STRUCT=&gt;2, :T_BIGNUM=&gt;2, :T_FILE=&gt;7,
:T_DATA=&gt;1443, :T_MATCH=&gt;85, :T_COMPLEX=&gt;1,
:T_NODE=&gt;1050, :T_ICLASS=&gt;37}
</code></pre><p>好懂的好懂，但還是有些怪怪的</p><ul><li>T_NODE: AST</li><li>T_DATA: interrupter自己的東西</li></ul><p>這裡就看我們知道的基本type就好</p><p>利用這個與gc開關可以來寫個簡單的benchmark看一段code產生多少object</p><pre tabindex=0><code class="language-ruby=" data-lang="ruby=">def allocate_count
    GC.disable
    before = ObjectSpace.count_objects
    yield
    after = ObjectSpace.count_objects
    after.each { |k,v| after[k] = v - before[k] }
    after[:T_HASH] -= 1 # probe effect - we created the before hash.
    after[:FREE] += 1 # same
    GC.enable
    after.reject { |k,v| v == 0 }
end

allocate_count { 100.times { &#39;hello&#39; + &#39;hi&#39; }}
</code></pre><p>同時也可以看現在有多少存活的object</p><pre tabindex=0><code class="language-ruby=" data-lang="ruby=">puts ObjectSpace.each_object.count
puts ObjectSpace.each_object(Numeric).count
puts ObjectSpace.each_object(Complex).count
ObjectSpace.each_object(Complex) { |c| puts c 
</code></pre><p>看一個type總共花的多少mem</p><pre tabindex=0><code>irb(main):057:0&gt; ObjectSpace.count_objects_size
{
:T_OBJECT =&gt; 198560,
:T_CLASS =&gt; 614784,
:T_MODULE =&gt; 66712,
:T_FLOAT =&gt; 160,
:T_STRING =&gt; 1578522,
:T_REGEXP =&gt; 122875,
:T_ARRAY =&gt; 630976,
:T_HASH =&gt; 165672,
:T_STRUCT =&gt; 160
...
</code></pre><p>看看這個物件佔了多少mem</p><pre tabindex=0><code>irb(main):062:0&gt; ObjectSpace.memsize_of(&#34;The quick brown fox jumps over the lazy dog&#34;)
40 # NOT ACCURATE
irb(main):063:0&gt; ObjectSpace.memsize_of(&#34;The quick brown fox&#34;)
40
irb(main):064:0&gt; ObjectSpace.memsize_of([])
40
irb(main):065:0&gt;ObjectSpace.memsize_of(Array.new(10_000) { :a })
80040
</code></pre><p>為什麼是40?
ruby vm的RVALUE大小就是40bytes</p><p>使用時機:</p><ul><li>各種try，以增加gc的知識</li><li>用 ObjectSpace.each_object 去check live objects</li><li>如果市面上的profiler不行了，可以hack這個來做profile</li></ul><h4 id=gcprofiler>GC::Profiler<a hidden class=anchor aria-hidden=true href=#gcprofiler>#</a></h4><p>ruby的gc是generational garbage collector</p><ul><li>看object活過幾次GC來對object分類<ul><li>活過一次就是old<ul><li>可以看old_objects(GC.stat)找有沒有memory leak發生<ul><li>如果這個值慢慢上升就是中了</li></ul></li></ul></li></ul></li><li>Minor GCs<ul><li>只挑new處理</li><li>核心思想是 通常object沒有幾個會活很久</li></ul></li></ul><p>GC.count就是從執行程式以來GC被執行的總次數，包含major與minor
GC.stat就是各種參數，除了GC的還有memory本身的各種數值</p><p>跑跑GC::profiler吧</p><pre tabindex=0><code class="language-ruby=" data-lang="ruby=">GC::Profiler.enable
require &#39;set&#39;
GC.start
GC::Profiler.report
GC::Profiler.disable
</code></pre><pre tabindex=0><code>GC 133 invokes.
Index Invoke    Time(sec)    Use Size(byte)    Total Size(byte)    Total Object    GC Time(ms)
1    1.966    801240    6315840    157896    2.33700000000003349498
</code></pre><p>invoke的值與GC.count一樣也就是，這是從執行程式以來GC被執行的總次數</p><p>使用時機:
如果gc跑太久，GC與GC::Profiler是個很好的開始</p><h4 id=derailed_benchmarks>derailed_benchmarks<a hidden class=anchor aria-hidden=true href=#derailed_benchmarks>#</a></h4><p>這個是看memory用量，可以追memory bloat</p><p>像<code>bundle exec derailed bundle:mem</code>
會列出每個gem用多少memory</p><pre tabindex=0><code>delayed_job: 18.9805 MiB (Also required by:
delayed/railtie, delayed_job_active_record)
delayed/performable_mailer: 17.8633 MiB
mail: 17.8555 MiB (Also required by: TOP)
mime/types: 12.9492 MiB (Also required by:
/Users/nateberkopec/.gem/ruby/2.3.0/gems/rest-client1.8.0/lib/restclient/request,
/Users/nateberkopec/.gem/ruby/2.3.0/gems/rest-client1.8.0/lib/restclient/payload)
mail/field: 2.0039 MiB
mail/message: 0.8477 MiB
delayed/worker: 0.6055 MiB
rails/all: 15.8125 MiB
rails: 7.5352 MiB (Also required by:
active_record/railtie, active_model/railtie, and 10
others)
rails/application: 5.3867 MiB
[… continues on and on]
</code></pre><p>跑app多次，看最後花了多少mem
<code>derailed exec perf:mem_over_time</code>
如果持續上升，memory leak</p><p>看object到底在哪產生的
<code>derailed exec perf:objects</code>
可以用來追哪個指令用memory太兇</p><p>使用時機:</p><ul><li>bundle:mem來check gem的mem占量，與減少mem bloat</li><li>trace mem leak</li></ul><h4 id=memory_profiler>memory_profiler<a hidden class=anchor aria-hidden=true href=#memory_profiler>#</a></h4><p>memory_profiler其實是derailed_benchmarks的backend</p><p>memory_profiler可以只對一段code做profile</p><pre tabindex=0><code class="language-ruby=" data-lang="ruby=">require &#39;memory_profiler&#39;
report = MemoryProfiler.report do
    # run your code here
end
report.pretty_print
</code></pre><p>之後的report會有</p><ul><li>Retained memory<ul><li>在跑profiler之前就在的object</li></ul></li><li>Allocated memory<ul><li>跑profiler時alloc的object<ul><li>高Allocated memory代表gc會跑比較多次，程式會變慢</li></ul></li></ul></li></ul><p>另外，memory_profiler跑出來的usage與會比ps看到的少，因為ruby有memory fragmentation</p><p>memory_profiler也可以profile c extendsion的memory</p><p>使用時機</p><ul><li>要追non-Rack-app與background jobs的mem issue</li><li>Rack的app可以用 derailed and rack-mini-profiler</li></ul><h3 id=front-end-chrome-timeline>front-end: chrome timeline<a hidden class=anchor aria-hidden=true href=#front-end-chrome-timeline>#</a></h3><p>對於end-user而言，Server response times(100ms~300ms)不是重點，因為占比很小(10%)
整個load time大概是1~3秒</p><ul><li><p>gzipped size對於<strong>花多久時間下載</strong>很重要</p></li><li><p>unzip 後的size對<strong>花多久時間parse與construct</strong>很重要</p></li><li><p>New Relic的real user monitoring (RUM)可以提供大概end-user感覺的page load time</p></li><li><p>Chrome Timeline可以看到每一步的實際狀況</p><ul><li>Chrome Timeline同時會記錄其他extensions的事件!! (記得關其他extendsion)</li></ul></li></ul><p>整個流程 (從browser的角度)</p><ol><li>DNS/TCP/SSL setup</li><li>download html</li><li>parsing html. 一但遇到其他資源就停下parse等載好跑完才會繼續parse<ul><li>css不會擋parse</li><li>js上async或是defer不會擋parse</li></ul></li><li>剛剛提到不會被擋的東西，preloader會在他簡單掃過後去preload!!</li></ol><p>所以我們要</p><ol><li>Don’t stop the parser.<ul><li>preloader會在parser跑之前先掃看有沒有可以先下載的東西<ul><li>head, script, &mldr;</li></ul></li><li>如果用js做動態生dom(script)，這樣preloader看不到!!</li></ul></li><li>Get out of the browser preloader’s way.<ul><li>preloader不吃<ul><li>iframe</li><li>webfont</li><li>HTML5 audio/video</li><li>css <code>@import</code></li></ul></li></ul></li><li>Use HTTP caching - but not too much.<ul><li>把常用的設成cache，自己打包(jquery&mldr;)<ul><li>如果賭user有大廠的api(來自google的cdn之類)<ul><li>有，沒事</li><li>沒有，整個parse被block!!</li></ul></li></ul></li></ul></li><li>Use the Resource Hint API.<ul><li>DNS Prefetch</li><li>Preconnect</li><li>Prefetch</li><li>Prerender</li></ul></li></ol><p>整個流程 (從網頁的角度)</p><ul><li>送request，等response<ul><li>這不會出現在timeline上，前面的空白就是這段時間</li><li>包含<ul><li>service response time (大約10ms)</li><li>network latency (大約10ms~300ms，看有沒有跨境)<ul><li>光速從新加坡到US都要花70ms!!</li></ul></li></ul></li></ul></li><li>Receive Response<ul><li>在收到任何byte就會有這一事件</li><li>這就是下載，完成下載後會有Finish Loading<ul><li>所以後面會看到很多這個event</li></ul></li></ul></li><li>Parse HTML<ul><li>把html轉成dom</li><li>下載需要的resource<ul><li><code>&lt;script src="/assets/application.js" async="async" ... /></code><ul><li>這個有加async，所以不會block整個parse</li><li>如果沒加parse會等下載完才繼續</li></ul></li><li>CSS不會block</li></ul></li><li>跑裡面寫的JS (會有對應的js)<ul><li>async會下載完直接跑(中斷parse)</li><li>defer會下載完等parse跑完再跑</li></ul></li></ul></li><li>Recalculate Styles<ul><li>parse CSS 把 DON 轉成 CSSOM</li><li>如果css還沒載完?<ul><li>先用browser預設的</li></ul></li><li>如果這邊花很久時間，代表css太複雜了</li></ul></li><li>Layout<ul><li>走訪DOM，算<ul><li>visibility</li><li>applicable CSSs tyles</li><li>relative geometry (width)</li></ul></li><li>複雜的CSS與HTML會讓這事件變久</li><li>layout thrashing(reflow)<ul><li>Any time you change the geometry of an element (its height, width, whatever), you trigger a layout event</li><li>一般browsers不知道哪邊要重算<ul><li>因此大部分都是全部重算(reflow)</li></ul></li><li>通常發生在<ul><li>js在搞dom</li><li>太多張stylesheets</li></ul></li><li><a href=https://gist.github.com/paulirish/5d52fb081b3570c81e3a>What forces layout / reflow</a></li></ul></li></ul></li><li>DomContentLoaded<ul><li>html與css與沒有標async的js(整個html)都跑完了 (<a href=https://zhuanlan.zhihu.com/p/25876048>照順序跑</a>)<ul><li>但其他資源還沒載完<ul><li>都載完會trigger load</li></ul></li><li><a href=https://testdrive-archive.azurewebsites.net/HTML5/DOMContentLoaded/Default.html>實際體驗</a></li></ul></li><li>但現在不會有任何東西在畫面上</li></ul></li><li>Paint<ul><li>把CSSOM畫在畫面上!!</li></ul></li></ul><p>之後可能還有其他CSS,JS
就會再產生對應的事件</p><p>怎麼用timeline來profile</p><ol><li>Hard reload (ctrl-shift-r) and load the Timeline with fresh data</li><li>Look at the pie graph for the entire page load<ul><li>Reduce Idle<ul><li>slow server responses</li><li>asset requests</li></ul></li><li>Reduce Loading<ul><li>HTML/CSS太大了</li></ul></li><li>Reduce Scripting<ul><li>通常是花在下載其他的script<ul><li><ul><li>async or defer</li></ul></li></ul></li><li>或是對js做profile</li></ul></li><li>Reduce Rendering and Painting<ul><li>這與css優化有關</li></ul></li></ul></li></ol><p>為什麼要整成一包?
HTML, TCP and latency are the problems, not bandwidth.
與render或是執行相比，network latency其實很重</p><p>一個inline的1MB page與有著100個external request的1MB page，一定是inline的最快，光是當下載就飽了
重點是什麼時候畫，什麼時間載入不是重點</p><p>對於end-user而言最重要的時間</p><ol><li>First paint: 雖然說只會看到框框，但還是很重要，這與人感知速度有關</li><li>First paint of text content</li><li>The load event</li></ol><p>Encoding</p><ol><li>http header</li><li>meta tag<ul><li>要放在第一個，不然會讓parse從頭再跑一次</li></ul></li><li>browser去猜</li></ol><p>Viewports
要放在第一個，不然之後有css會讓browser去reflow</p><p>css first
如果有js的head，且沒有async，這種情況下把js的head放css前面，這樣會讓css的下載被block</p><h3 id=3rd-party-new-relic>3rd-party: New Relic<a hidden class=anchor aria-hidden=true href=#3rd-party-new-relic>#</a></h3><h4 id=development--production-環境會有差異的原因>development & production 環境會有差異的原因<a hidden class=anchor aria-hidden=true href=#development--production-環境會有差異的原因>#</a></h4><ul><li>Application settings<ul><li>code reloading</li></ul></li><li>Caching behavior</li><li>Differences in data<ul><li>production資料量一定比較大(用includes)</li></ul></li><li>Network latency<ul><li>大概數字<ul><li>在同一個城市: 10ms</li><li>在兩個州之間: 20ms</li><li>從US東到US西: 100ms</li><li>到世界的另一邊: up to 300ms</li><li>如果是手機網路，可能要再乘4倍</li></ul></li></ul></li><li>JavaScript and devices<ul><li>同樣的js code不同的裝置<ul><li>PC</li><li>mobile: 跑起來比較痛苦</li></ul></li></ul></li><li>System configuration and resources<ul><li>同樣的container可以跑在不同硬體上</li><li>程式用不同的compiler或是compile flag編</li></ul></li><li>Virtualization<ul><li>negatively and unpredictably impact performance when one virtualized server is hogging up the resources available</li></ul></li></ul><h4 id=new-relic-profile-in-production-env>New Relic: profile in production env<a hidden class=anchor aria-hidden=true href=#new-relic-profile-in-production-env>#</a></h4><p>Transactions: response
Real-User Monitoring (also RUM and Browser monitoring):</p><ul><li>在每頁插入JS測時間<ul><li>NavigationTimingAPI</li><li>Events set include domContentLoaded, domfomplete, requestStart and responseEnd</li></ul></li></ul><h4 id=process-time>process time<a hidden class=anchor aria-hidden=true href=#process-time>#</a></h4><p>The web transaction response time graph</p><p>預設時間是30mins，我們要看時間的越長越好，最好是一個月，new relic最長到7天，但也夠了</p><p>純後端性能</p><table><thead><tr><th>App server avg response time</th><th>Status</th></tr></thead><tbody><tr><td>&lt; 100ms</td><td>Fast!</td></tr><tr><td>&lt; 300ms</td><td>Average</td></tr><tr><td>> 300ms</td><td>Slow!</td></tr></tbody></table><p>如果是JSON的API server，可以把時間再減半</p><p>後端加前端性能</p><table><thead><tr><th>Browser avg load time</th><th>Status</th></tr></thead><tbody><tr><td>&lt; 3 sec</td><td>Fast!</td></tr><tr><td>&lt; 6 sec</td><td>Average</td></tr><tr><td>> 6 sec</td><td>Slow!</td></tr></tbody></table><p>Next, I’m considering the shape of the response time graph
<img loading=lazy src=https://i.imgur.com/1QDuC56.png alt>
重點是在每個部分中，時間都花到哪裡去了</p><ul><li>一般來說應該花在ruby上最多</li><li>如果database, web external, or other processes比較多就是有問題<ul><li>web external就是有人在等外部API</li><li>request queueing代表需要更多server</li></ul></li></ul><p><img loading=lazy src=https://i.imgur.com/64zJgBX.png alt></p><p>這裡是看哪次request(transaction)最特別</p><p>看最左(95th Percentiles)，去做優化
但也要記得看最右，為什麼這麼快，Are they asset requests? Redirects? Errors?
Are they asset requests? Redirects? Errors?</p><table><thead><tr><th>Requests per minute</th><th>Scale</th></tr></thead><tbody><tr><td>&lt; 10</td><td>Should only have 1 server/Heroku dyno.</td></tr><tr><td>10 - 1000</td><td>Average</td></tr><tr><td>> 1000</td><td>High. “Just add more servers” may not work anymore.</td></tr></tbody></table><p>大於1000時就要考慮怎麼處理databases或是cache stores，以及引入devops</p><h4 id=transactions>Transactions<a hidden class=anchor aria-hidden=true href=#transactions>#</a></h4><p>如果requests-per-minute scale靠前，用most time consuming排序(80%時間花在20%的controller)</p><p>requests-per-minute小，用slowest average response time排序</p><p>因為把一個100ms的response變成10ms對user體驗沒有太大影響(所以注意超過500ms的request)</p><h4 id=database>database<a hidden class=anchor aria-hidden=true href=#database>#</a></h4><p>用most time consuming看有沒有query太久</p><p>常見病症</p><ul><li>Lots of time in #find<ul><li>Pay attention to the “time consumption by caller” graph<ul><li>where is this query being called the most?<ul><li>Go check out those controllers and see<ul><li>where的欄位沒有index</li><li>N+1 query</li></ul></li></ul></li></ul></li></ul></li><li>SQL - OTHER<ul><li>Rails periodically issues queries<ul><li>別管他們</li></ul></li></ul></li></ul><h4 id=external-services>External Services<a hidden class=anchor aria-hidden=true href=#external-services>#</a></h4><p><img loading=lazy src=https://i.imgur.com/OkHYBqz.png alt></p><p>Most Ruby applications will block on network requests
一般Rails會被外部API的request給block
根據不同的timeout，可以delay載入大概200ms~500ms，如果是95th percentile還可以到20秒</p><p>一個是用background worker去跑，把東西放到cache
或是設定<a href=https://martinfowler.com/bliki/CircuitBreaker.html>Circuit Breaker</a>，如果看到request一直timeout讓之後的request直接fail</p><h4 id=gc-stats-and-reports>GC stats and Reports<a hidden class=anchor aria-hidden=true href=#gc-stats-and-reports>#</a></h4><p>不準，忘了他</p><h4 id=browser--real-user-monitoring-rum>Browser / Real user monitoring (RUM)<a hidden class=anchor aria-hidden=true href=#browser--real-user-monitoring-rum>#</a></h4><p><img loading=lazy src=https://i.imgur.com/lU9IXtn.png alt></p><p>切成“Browser page load time”，之後看每個元件的average load time</p><ul><li>Request queueing<ul><li>通常最多10-20ms</li></ul></li><li>Web application<ul><li>就是你的app，但注意到這裡的時間占比很小</li></ul></li><li>Network<ul><li>通常比 response + queueing 還久</li><li>這是算雙向的時間</li></ul></li><li>DOM Processing<ul><li>花很多時間 > Web application+Request queueing</li><li>算load finish到DOMContentReady</li><li>這個時候只是html parse完<ul><li>後面還有其他CSS與JS</li></ul></li><li>這個時候畫面還是白的</li></ul></li><li>Page Rendering<ul><li>算DOMContentReady到load<ul><li>DOMContentReady就是$(document).ready</li><li>load就是所有資源都好了才會動</li></ul></li><li>到load之前，browser可能會顯示一些畫面</li></ul></li></ul><h2 id=turbolinks--html-over-the-wire>Turbolinks & &ldquo;HTML-over-the-wire&rdquo;<a hidden class=anchor aria-hidden=true href=#turbolinks--html-over-the-wire>#</a></h2><p>HTML-over-the-wire與SPA差在一個傳HTML一個傳資料</p><p>一般來說，rails app (大約1秒)</p><ul><li>return a response in 100-300ms,</li><li>spend about 200ms loading the HTML and CSSOM, a few hundred more ms renderingand painting</li><li>then likely loads of JS scripting tied to the onload event.</li></ul><p>Turbolinks可以把上面的時間減少200-700ms</p><p>代價</p><ul><li>不能用一般的方式寫js<ul><li>idempotent function</li><li>不能往ready一直掛hook<ul><li>被Turbolinks拿去用了!! (load也被拿走了)<ul><li>所以要用其他<a href=https://github.com/turbolinks/turbolinks-classic#events>事件</a></li></ul></li></ul></li></ul></li><li>不能與其他client side JS frameworks共存<ul><li>load被拿走了</li></ul></li><li>做Integration testing會很痛苦</li><li>在mobile上基本沒用</li><li>不能offline(SPA可以)</li></ul><p>常見錯誤</p><ol><li>確信這個page有被Turbolinks<ul><li>開console看有沒有<code>Navigated to http://www.whatever.com/foo</code><ul><li>有就gg</li></ul></li></ul></li><li>用dom append的方式改網頁<ul><li>因為Turbolinks是回傳整個html，所以應該<ul><li>用controller產生資料帶到erb，之後生html</li><li>不是一直用js塞</li></ul></li></ul></li></ol><h2 id=關於反應時間>關於反應時間<a hidden class=anchor aria-hidden=true href=#關於反應時間>#</a></h2><p>0.1秒: 很快
1秒: 可以接受，也許有人會覺得慢
10秒: 人能夠忍耐的上限，需要feedback讓user知道跑到哪了
<a href=https://www.nngroup.com/articles/response-times-3-important-limits/>source</a></p><h2 id=benchmark>benchmark<a hidden class=anchor aria-hidden=true href=#benchmark>#</a></h2><p>benchmark: 測code花多少時間或是花多少資源</p><p>也許某段code的benchmark好，但是其實這段code的占比不大，那就不用特別去改
還有可能是單單benchmark快，但是對整體沒有影響甚至是拖累整體</p><pre tabindex=0><code class="language-ruby=" data-lang="ruby=">require &#39;benchmark/ips&#39;
Benchmark.ips do |x|
    SORTED_ARRAY = Array.new(10_000) { rand(100_000) }.sort!
    array_size = SORTED_ARRAY.size
    # Typical mode, runs the block as many times as it can
    x.report(&#34;bsearch1&#34;) { bsearch1(SORTED_ARRAY, rand(array_size))}
    x.report(&#34;bsearch2&#34;) { bsearch2(SORTED_ARRAY, rand(array_size))}
    x.compare!
end
</code></pre><p>整個網站</p><ul><li>ab</li><li>wrk</li></ul><h2 id=performance之於企業>performance之於企業<a hidden class=anchor aria-hidden=true href=#performance之於企業>#</a></h2><ul><li>Create a Performance Culture<ul><li>用$衡量效率</li><li>設定 a front-end load time<ul><li>DOMContentLoaded</li><li>window.load</li><li>start render time</li></ul></li><li>設定 MART and/or M95RT<ul><li>Set a maximum average response time and/or a maximum 95th percentile response time for your server responses</li><li>it’s important to capture what’s going on in the “long tail” as well as what’s happening to the average case.</li></ul></li><li>設定 a page weight<ul><li>cannot exceed <code>&lt;projected user bandwidth in megabytes/second> / &lt;load time budget in seconds></code></li></ul></li><li>設定 integration costs</li><li>Add automated performance and page weight tests<ul><li>An acceptance test<ul><li>make a GET request to this page<ul><li>record two or three numbers<ul><li>Server response time</li><li>User page load timings (DOMContentLoaded & load)</li></ul></li></ul></li><li>benchmark &ldquo;hot code&rdquo;</li></ul></li><li>Run the performance acceptance tests separately from your unit and acceptance/integration tests.</li><li>這一定有灰色地帶</li><li>有第三方服務<ul><li>Blazemeter</li><li>Loader.io</li></ul></li></ul></li></ul></li></ul><h2 id=db-optimization>DB optimization<a hidden class=anchor aria-hidden=true href=#db-optimization>#</a></h2><p>加index的好地方</p><ul><li>Foreign keys</li><li>Primary keys</li><li>Polymorphic relationships</li><li>updated_at<ul><li>給 Russian Doll caching</li></ul></li></ul><p>當覺得sql效能怪怪的，用EXPLAIN</p><p>MVCC會產生新資料與舊資料，通常在transaction好了之後舊資料會被清掉，但總是會有漏的</p><p>VACUUM!!</p><ul><li>省空間</li><li>讓query planner更有效率</li></ul><p>scale的時候，除了process變多，還有
process是怎麼與shared resource溝通</p><ul><li>database</li><li>Redis, memcache, and other key-value stores</li></ul><p>這是重點的理由是
連線數量有限制!!
要記的算!!</p><p>在test的時候，可以放鬆ACID，加快測試速度</p><ul><li>db放RAMdisk</li><li>把fsync 與 synchronous commit關掉</li></ul><h2 id=rails-slow>Rails slow?<a hidden class=anchor aria-hidden=true href=#rails-slow>#</a></h2><ul><li>log to disk</li><li>useless gems<ul><li>Sprockets</li><li>ActionMailer</li><li>&mldr;</li></ul></li><li>useless rack middleware<ul><li>Rack::Sendfile</li><li>ActionDispatch::Cookies</li><li>ActionDispatch::Session::CookieStore</li><li>ActionDispatch::Flash</li><li>ActionDispatch::RemoteIp</li><li>ActionDispatch::ShowExceptions</li><li>ActionDispatch::DebugExceptions</li><li>ActionDispatch::Callbacks</li><li>ActionDispatch::RequestId</li><li>Rack::Runtime</li><li>&mldr;</li></ul></li></ul><h2 id=exception-slow>exception slow!!<a hidden class=anchor aria-hidden=true href=#exception-slow>#</a></h2><p>Exceptions should not be used for flow control, use throw/catch for that.</p><p>This reserves exceptions for true failure conditions.</p><pre tabindex=0><code class="language-ruby=" data-lang="ruby=">catch(:done) do
    i = 0
    loop do
        i += 1
        throw :done if i &gt; 100_000
    end
end
finish_up
</code></pre><h2 id=memory-bloat>memory bloat<a hidden class=anchor aria-hidden=true href=#memory-bloat>#</a></h2><p>要看什麼?</p><ul><li>Resident Set Size (RSS): process用到的記憶體 (包含shared)<ul><li>Shared Memory</li><li>Private Memory: 包含forked的child<ul><li>Real Memory = Shared Memory + Private Memory</li></ul></li></ul></li></ul><p>怎麼看?</p><ul><li>ps</li><li>get_process_mem</li><li>Oink</li></ul><p>減少memory bloat</p><ul><li>Beware Big Allocations<ul><li>不是說GC完所有不用的mem都會還回去<ul><li>可以看成還記憶體很慢</li></ul></li><li>替代方案是streaming: file.gets</li></ul></li><li>Gemfile Auditing<ul><li>檢查gem: derailed_benchmarks</li></ul></li><li>jemalloc<ul><li><a href=https://www.cyningsun.com/07-07-2018/memory-allocator-contrasts.html>ptmalloc、tcmalloc与jemalloc对比分析</a></li></ul></li><li>GC Parameters</li></ul><h2 id=memory-leaks>Memory Leaks<a hidden class=anchor aria-hidden=true href=#memory-leaks>#</a></h2><p>有不同等級</p><ul><li>Managed Ruby object leaks</li><li>C-extension leaks</li><li>Leaks in Ruby itself (the VM)</li></ul><p>| Item | Memory bloat | Memory leaks |
| ———— | —— | ————— |
| Allocated memory is actually required | Yes | No |
| Growth | Fast and large | Slow and steady |
| Levels off | Eventually | Never |</p><p>一般來說大概2~3小時mem用量會平緩下來，最慢大概24小時
沒有就有可能leak</p><p>怎麼重現</p><ol><li>調高環境的記憶體上限與設定不要把process砍掉</li><li>放著跑，看用量有沒有收斂</li></ol><p>siege做多次測試，之後看</p><ul><li>RSS memory usage</li><li><code>GC.stat[:heap_live_slots]</code><ul><li>這是有多少slot被object占用</li><li>如果RSS上升，但這個不變<ul><li>可能是C-extension leak</li></ul></li></ul></li><li><code>GC.stat[:heap_free_slots]</code><ul><li>這是沒有被object占用的slot</li><li>如果這個數字大，代表<ul><li>ruby vm沒有把mem還給記憶體</li><li>有人alloc大量記憶體之後就不用了</li><li>這是 memory bloat</li></ul></li></ul></li><li><code>ObjectSpace.count_objects</code><ul><li>這是目前在ruby vm中的object數量</li><li>如果有個type的object一直漲，代表<ul><li>Ruby memory leak</li></ul></li></ul></li></ul><p>這裡有一個小程式可以看上面的訊息</p><pre tabindex=0><code class="language-ruby=" data-lang="ruby=">Thread.new do
    logger = Logger.new(&#39;mem_log.txt&#39;)
    logger.formatter = proc { |sev, date, prog, msg| msg }
    headers = [
        &#34;RSS&#34;,
        &#34;Live slots&#34;,
        &#34;Free slots&#34;,
        ObjectSpace.count_objects.keys
    ].flatten
    logger.info headers.join(&#34;,&#34;)
    while true
        pid = Process.pid
        rss = `ps -eo pid,rss | grep #{pid} | awk &#39;{print $2}&#39;`
        memory_info = [
            rss.strip,
            GC.stat[:heap_live_slots],
            GC.stat[:heap_free_slots],
            ObjectSpace.count_objects.values
        ].flatten
        logger.info memory_info.join(&#34;,&#34;)
        logger.info &#34;\n&#34;
        sleep 5
    end
end
</code></pre><p>把上面的code放到config/initializers，之後就會有csv
這樣就可以用seige打打看，生10~15k的資料，之後就可以分析了</p><ul><li>Managed Ruby object leaks<ul><li>heap live slots & RSS 上升, heap free slots不高</li><li>用memory_profiler看<code> retained objects by location</code></li></ul></li><li>C-extension leaks<ul><li>heap live slots & heap free slots不變, RSS 上升</li><li>Ruby的Heap dumping</li><li>jemalloc Introspection</li></ul></li><li>Leaks in Ruby itself (the VM)<ul><li>heap live slots & heap free slots不變, RSS 上升<ul><li>但是找不到任何C-extension leak!!</li></ul></li><li>直接回報</li></ul></li></ul><p>真的不行了就Worker-Killers</p><h2 id=memory-fragmentation>Memory Fragmentation<a hidden class=anchor aria-hidden=true href=#memory-fragmentation>#</a></h2><p>Memory fragmentation會讓mem usage對數上升，直到一個可怕的limit</p><p>主要原因在於ruby沒辦法移動meme中的obj</p><p>ObjectSpace就是ruby vm的mem，slot存的就是RVALUE(40 bytes)，也就是object的指標
RVALUE會被集合在一起成一個page</p><p>所以ruby其實本身也有Fragmentation
看到GC.stat</p><ul><li>heap_live_slots: 代表現在有被RVALUE占用的slot有多少 aka 現在有多少object活著</li><li>heap_eden_pages<ul><li>eden_page是至少有一個活著的slot的page</li><li>tomb_page就是都沒有一個活著的slot的page<ul><li>tomb_page才可以還給OS</li></ul></li></ul></li><li>heap_sorted_length<ul><li>一開始分配mem都是一塊一塊配上去<ul><li>這個以分配的長度是heap_sorted_length</li></ul></li><li>但是如果中間有幾塊被free了&mldr;<ul><li>heap_sorted_length不變，因為不是連續的</li><li>但是中間的就沒辦法用了 (Fragmentation)</li></ul></li></ul></li></ul><p>所以可以用兩種方式看Fragmentation</p><ul><li>heap_live_slots / heap_eden_pages的slot數量</li></ul><pre tabindex=0><code class="language-ruby=" data-lang="ruby=">GC.stat[:heap_live_slots] # 24508
GC.stat[:heap_eden_pages] # 83
GC::INTERNAL_CONSTANTS[:HEAP_PAGE_OBJ_LIMIT] # 408
# 1 - live_slots / (eden_pages * slots_per_page)
# 24508 / (83 * 408) = 72.3
# 100% - 72.3% = 27.7%
</code></pre><ul><li><code>GC.stat[:heap_sorted_length]</code>/<code>GC.stat[:heap_sorted_length]</code></li></ul><p>per-thread memory arena</p><ol><li>We call malloc in a thread</li><li>The thread attempts to obtain the lock for the memory arena it accessed previously</li><li>If that arena is not available, try the next memory arena</li><li>If none of the memory arenas are available, create a new arena and use that<ul><li>同時加回去arena的list</li></ul></li></ol><p>所以arena其實就是記憶體!!
但現在如果沒有限制arena數量的話</p><ol><li>變成有好幾塊小塊的記憶體沒辦法合併</li><li>ruby的ptr不能被移動 (RVALUE的ptr直接指到mem)</li></ol><p>arena少，mem usage少，但contention會變多</p><p>所以下次遇到</p><ol><li>Reduce Memory Arenas(改MALLOC_ARENA_MAX)</li><li>Use jemalloc</li><li>Compacting GC (夢想)</li></ol><h2 id=關於application-server本身>關於application server本身<a hidden class=anchor aria-hidden=true href=#關於application-server本身>#</a></h2><p>aws與heroku很好scale，也同時讓人容易過度scale</p><blockquote><p>Scaling increases throughput, not speed.
scale只有在有queue時才會提升response times</p></blockquote><p>所以別只看response times做scale，要看有多少queue的request</p><p>因為不同server的io model與process/thread model不同，讓server在scale上有巨大的差別</p><h3 id=the-life-of-a-request>The life of a request<a hidden class=anchor aria-hidden=true href=#the-life-of-a-request>#</a></h3><p>重點是request會被queue在哪裡</p><ol><li>load balancer</li><li>Heroku router<ul><li>it will then wait up to five seconds for that dyno to accept the request and open a connection.</li></ul></li><li>available host<ul><li>backlog: the socket on the dyno will accept the connection even if the webserver is busy processing other requests.</li></ul></li></ol><p>上面最重要的有兩點</p><ol><li>router會等5秒直到成功連線</li><li>request可以活在host的backlog中 (server要有這功能)</li></ol><h3 id=server在scale上差在>server在scale上差在?<a hidden class=anchor aria-hidden=true href=#server在scale上差在>#</a></h3><p>主要是處理兩件事</p><ol><li>slow client protection<ul><li>request buffering，會等req下載好了才會轉給app</li></ul></li><li>slow response protection<ul><li>kind of concurrency - either multithreading or multiprocess/forking<ul><li>至少不會卡IO (如果thread有特別處理)</li><li>但如果是multithread會因為GIL，讓其他人不能用cpu<ul><li>所以ruby的multithreading對cpu-bound的request不好</li></ul></li></ul></li></ul></li></ol><p>這樣看下來只有</p><ul><li>Puma in clustered mode</li><li>Phusion Passenger 5
可以用於scale server</li></ul><h4 id=設定server參數>設定server參數<a hidden class=anchor aria-hidden=true href=#設定server參數>#</a></h4><p>目標</p><ul><li>讓memory 與 CPU使用最大化</li><li>讓throughput最大化</li></ul><p>要4個要注意的</p><ul><li>process數目<ul><li>process才是真的平行</li><li>建議一台最少3個process<ul><li>最多?<ul><li>要看mem與cpu<ul><li>mem<ul><li>不能太多mem，不然會overcommit與swap</li><li>測ruby app的mem用量<ul><li>放著跑12~24小時</li><li>用ps看</li></ul></li><li>procs = <code>(TOTAL_RAM / (RAM_PER_PROCESS * 1.2))</code></li></ul></li><li>cpu<ul><li>每5分鐘或15分鐘看cpu load<ul><li>如果靠近或是到100%，就減少process數量</li></ul></li><li>procs = 1.2~1.5倍的hyperthread</li></ul></li></ul></li><li>一般來說是8個</li></ul></li></ul></li><li>多process的好處是?<ul><li>可以讓OS做load balance</li><li>比讓load balancer做load balance還要好<ul><li>OS可以知道process的狀態!!</li></ul></li></ul></li></ul></li><li>thread數量<ul><li>ruby的thread只能處理IO(db)</li><li>所以要多少<ul><li>最多5~6個</li><li>再多就會<ul><li>碰Amdahl’s law</li><li>mem會被吃爆(看mem fragmentation)</li></ul></li></ul></li></ul></li><li>copy-on-write<ul><li>在init好了之後fork (preload)</li><li>但省的空間沒有想像的多<ul><li>如果用大分頁，只要改一個bit就會被copy，導致copy大量資料<ul><li>想想ruby vm怎麼用page的，好幾個object塞同一個page</li></ul></li><li>fragmentation!!</li></ul></li></ul></li><li>Container size<ul><li>就是cpu與mem要多少</li><li>針對<ul><li>你的app需求 (吃mem? 吃cpu?)</li><li>前面提到的process數量<ul><li>3process，ruby app一個大約300MB<ul><li>所以mem至少要1G</li></ul></li></ul></li></ul></li></ul></li></ul><p>步驟</p><ol><li>找出1 process跑5 thread要多少mem</li><li>一個child process需要<code> (TOTAL_RAM / (RAM_PER_PROCESS * 1.2))</code><ul><li>一台需要3個process，以此推算出需要的總mem</li></ul></li><li>確認hyperthread的數量夠<ul><li>child process的數量要等於1.25~1.5的hyperthread</li></ul></li><li>monitor cpu與mem usage，調整process數量與container的規格</li></ol><h2 id=gc>gc<a hidden class=anchor aria-hidden=true href=#gc>#</a></h2><p>Generational GC認為通常都是年輕的object掛掉，所以分成兩個gc</p><ul><li>minor gc只處理new object(活不超過3以下的object)<ul><li>在沒有free slot啟動<ul><li>處理new object、在remember set的object、沒有write barrier的object<ul><li>remember set: 一群old object但是有new object的ptr</li><li>write barrier: ruby runtime與object之間的interface</li></ul></li></ul></li></ul></li><li>major gc處理所有object<ul><li>在下面2種case下啟動<ul><li>跑完minor gc後還是沒有free slot</li><li>4個limit的其中一個超標<ul><li>malloc_increase_bytes_limit<ul><li>malloc_increase_bytes<ul><li>當RVALUE不夠存時需要alloc資料到其他地方</li><li>malloc_increase_bytes就是他的大小</li></ul></li></ul></li><li>oldmalloc_increase_bytes_limit<ul><li>與malloc_increase_bytes同樣道理但是只針對old</li></ul></li><li>old_objects_limit<ul><li>old object的slot</li></ul></li><li>remembered_wb_unprotected_objects_limit<ul><li>remembere set與沒有write barrier的object</li></ul></li></ul></li></ul></li></ul></li></ul><p>trace gc count可以看r background job是不是會一直觸發gc
像下面就是可以用來trace的midleware</p><pre tabindex=0><code class="language-ruby=" data-lang="ruby=">class GCCounter
def initialize(app)
    @app = app
end
def call(env)
    gc_counts_before = GC.stat.select { |k,v| k =~ /count/
    @app.call(env)
    gc_counts_after = GC.stat.select { |k,v| k =~ /count/
    puts gc_counts_before.merge(gc_counts_after) { |k, vb, va| va - vb }
end
end
</code></pre><p>ruby的ObjectSpace(heap)就是記憶體，一個ptr(RVALUE)對到一個slot，好多個slot變成一個page</p><p>heap_sorted_length是目前alloc的連續長度(想像怎麼實作vma的)
heap_allocated_pages是只有多少page(已經變成page的mem)
heap_allocatable_pages是指可以再有多少page(已經malloc了的mem)</p><p>heap_live_slots是指現在有多少object
heap_free_slots是指有多少空的slot
heap_final_slots是指多少slot被finalize
heap_marked_slots是指old的object與沒有write barrier的物件(c-extendsion的mem)</p><p>tomb_pages就是slot都是free (可以還給OS)
eden_pages就是至少有一個live slot</p><p>tune gc的目的</p><ul><li>減少memory bloat</li><li>減少跑gc的時間</li></ul><p>核心想法: 讓free slot不要太多</p><p>調</p><ul><li>RUBY_GC_HEAP_FREE_SLOTS_GOAL_RATIO</li><li>RUBY_GC_HEAP_INIT_SLOTS</li><li>RUBY_GC_HEAP_FREE_SLOTS_MAX_RATIO</li><li>RUBY_GC_HEAP_FREE_SLOTS_MIN_RATIO</li></ul><pre tabindex=0><code class="language-c=" data-lang="c=">RUBY_GC_HEAP_FREE_SLOTS_GOAL_RATIO=0.1
RUBY_GC_HEAP_FREE_SLOTS_MAX_RATIO=0.2
RUBY_GC_HEAP_FREE_SLOTS_MIN_RATIO=0.05
RUBY_GC_HEAP_INIT_SLOTS=1000000
</code></pre><h2 id=orm>orm<a hidden class=anchor aria-hidden=true href=#orm>#</a></h2><p>核心概念: avoiding instantiating ActiveRecord objects</p><ul><li>如果很多records，不要用each一筆一筆讀，mem會起飛<ul><li>find_each and in_batches loads them in batches</li></ul></li><li>Select Only What You Need</li><li>Preloads somehow<ul><li>eager_load use LEFT OUTER JOIN when eager loading the model associations.</li><li>includes 最先考慮他</li><li>preload 會產生qeury把指定的model載入，之後透過ruby把剩下的接起來</li><li>Each eager load increases the number of instantiated objects, and in turn slows down the query<ul><li>Each eager load increases the number of instantiated objects, and in production-like data turn slows down the query</li></ul></li></ul></li><li>Don’t Use Many Queries When One Will Do<ul><li>create too many ActiveRecord objects is when doing mass updates</li><li>如果可以一行sql處理掉，就讓sql處理<ul><li>update_all, destroy_all</li></ul></li></ul></li><li>Do Math In The Database<ul><li>如果需要統計可以留給db</li></ul></li><li>N+1<ul><li>用production的資料，跑看sql的log</li><li>找SQL哪裡生出來的(看下面的code)</li><li>跑rack-mini-profiler</li></ul></li></ul><pre tabindex=0><code class="language-ruby=" data-lang="ruby=">module LogQuerySource
    def debug(*args, &amp;block)
        return unless super
        
        backtrace = Rails.backtrace_cleaner.clean caller
        relevant_caller_line = backtrace.detect do |caller_line|
        !caller_line.include?(&#39;/initializers/&#39;)
        end
        if relevant_caller_line
            logger.debug(&#34; -&gt; #{ relevant_caller_line.sub(&#34;#{
        end
    end
end

ActiveRecord::LogSubscriber.send :prepend, LogQuerySource
</code></pre><p>書上的例子是<a href=https://github.com/rubygems/rubygems.org/pull/1189/files>這個</a>
partial會對每個collections的東西call find_by!!</p><p>using an ActiveRecord query method like find_by which is called on every element in a collection - is extremely common
只要用在OOOs中的其中一個就有N+1的風險</p><p>流程是</p><ol><li>Methods on a model trigger SQL queries (by using the ActiveRecord API)</li><li>those methods get called in the view</li><li>they end up being used in a partial or something that gets iterated for every element in a collection,</li><li>N+1</li></ol><p>解法</p><ul><li>Instead of doing using ActiveRecord methods that trigger SQL queries, we’re going to rewrite this method to use regular Arrays and Enumerable methods.</li><li>Do not use ActiveRecord query methods inside models, especially not on a model’s instance methods.<ul><li>Use them only in controllers and helpers.</li></ul></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://littlebees.github.io/tags/rails/>Rails</a></li></ul><nav class=paginav><a class=prev href=https://littlebees.github.io/2022/03/mit-6.824%E7%AD%86%E8%A8%98/><span class=title>« Prev</span><br><span>mit 6.824筆記</span>
</a><a class=next href=https://littlebees.github.io/2022/01/%E5%A5%94%E8%B7%91%E5%90%A7linux%E5%85%A7%E6%A0%B8ch2~ch5%E6%91%98%E9%8C%84/><span class=title>Next »</span><br><span>奔跑吧linux內核ch2~ch5摘錄</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://littlebees.github.io/>記事本</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>